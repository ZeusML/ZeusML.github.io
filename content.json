{"meta":{"title":"Coding","subtitle":null,"description":null,"author":"ZeusML","url":"http://yoursite.com"},"pages":[{"title":"All categories","date":"2018-08-02T02:57:30.000Z","updated":"2018-08-06T08:56:14.006Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-08-02T02:55:10.000Z","updated":"2018-08-06T08:56:29.280Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2018-08-02T04:44:37.000Z","updated":"2018-08-02T04:46:01.797Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"hello world!!!"},{"title":"TopX","date":"2019-04-16T09:34:42.485Z","updated":"2018-08-08T02:45:59.609Z","comments":true,"path":"top/index.html","permalink":"http://yoursite.com/top/index.html","excerpt":"","text":"AV.initialize(\"xjvmRTh5uk9TGSBe2OmBUrG2-gzGzoHsz\", \"DUf4ffoL1SMt7dTCL9gnvpDV\"); var time=0 var title=\"\" var url=\"\" var query = new AV.Query('Counter'); query.notEqualTo('id',0); query.descending('time'); query.limit(1000); query.find().then(function (todo) { for (var i=0;i"}],"posts":[{"title":"spring集成jetty","slug":"SpringBoot之Scheduled","date":"2019-04-23T00:59:10.000Z","updated":"2019-04-23T09:05:01.197Z","comments":true,"path":"2019/04/23/SpringBoot之Scheduled/","link":"","permalink":"http://yoursite.com/2019/04/23/SpringBoot之Scheduled/","excerpt":"","text":"Demo 启动类 在启动类上面添加@EnableScheduling注解开启定时功能 123456789@SpringBootApplication@EnableSchedulingpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; Service 12345678@Componentpublic class ScheduleService &#123; @Scheduled(cron = \"0/1 * * * * ?\") public void sc1() throws InterruptedException &#123; System.out.println(Thread.currentThread().getName() + \" | sc1 \" + System.currentTimeMillis()); &#125;&#125; console Problem 由图可见，定时任务都是由一个线程来执行，那么会存在以下问题 一个项目中有多个定时任务时，他们是并行执行的还是串行执行的？ 如果默认是串行的 那么有相同的crond表达式的定时任务之间，有先后顺序么？ 某个任务的阻塞是否会影响后面的任务？ 如果需要他们并行执行，可以怎么做？ 如果是并发执行的 是新创建线程还是采用线程池来复用呢？ 在并发执行时，假设有个每秒执行一次的任务，但是它执行一次消耗的时间大于1s时，这个任务的表现时怎样的呢？不断地新增线程来执行还是等执行完毕之后再执行下一次的呢? 再次不做测试，直接给出结论 默认情况下只有一条线程来执行，所以是串行的 某个任务阻塞会影响后面的任务 如果需要并行则在对应的方法上加@Async注解（启动类要添加@EnableAsync），不推荐此方法 自定义线程池1234567@Bean public TaskScheduler taskScheduler()&#123; ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler(); taskScheduler.setPoolSize(20); taskScheduler.setThreadNamePrefix(\"thread-zml-\"); return taskScheduler; &#125; 或者 12345678910@Beanpublic AsyncTaskExecutor asyncTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setThreadNamePrefix(\"yhh-schedule-\"); executor.setMaxPoolSize(10); executor.setCorePoolSize(3); executor.setQueueCapacity(0); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.AbortPolicy()); return executor;&#125; 配合@Async @Scheduled注解各参数详解 @Scheduled注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(Schedules.class)public @interface Scheduled &#123; /** * A special cron expression value that indicates a disabled trigger: &#123;@value&#125;. * &lt;p&gt;This is primarily meant for use with $&#123;...&#125; placeholders, allowing for * external disabling of corresponding scheduled methods. * @since 5.1 */ String CRON_DISABLED = \"-\"; /** * A cron-like expression, extending the usual UN*X definition to include triggers * on the second as well as minute, hour, day of month, month and day of week. * &lt;p&gt;E.g. &#123;@code \"0 * * * * MON-FRI\"&#125; means once per minute on weekdays * (at the top of the minute - the 0th second). * &lt;p&gt;The special value &#123;@link #CRON_DISABLED \"-\"&#125; indicates a disabled cron trigger, * primarily meant for externally specified values resolved by a $&#123;...&#125; placeholder. * @return an expression that can be parsed to a cron schedule * @see org.springframework.scheduling.support.CronSequenceGenerator */ String cron() default \"\"; /** * A time zone for which the cron expression will be resolved. By default, this * attribute is the empty String (i.e. the server's local time zone will be used). * @return a zone id accepted by &#123;@link java.util.TimeZone#getTimeZone(String)&#125;, * or an empty String to indicate the server's default time zone * @since 4.0 * @see org.springframework.scheduling.support.CronTrigger#CronTrigger(String, java.util.TimeZone) * @see java.util.TimeZone */ String zone() default \"\"; /** * Execute the annotated method with a fixed period in milliseconds between the * end of the last invocation and the start of the next. * @return the delay in milliseconds */ long fixedDelay() default -1; /** * Execute the annotated method with a fixed period in milliseconds between the * end of the last invocation and the start of the next. * @return the delay in milliseconds as a String value, e.g. a placeholder * or a &#123;@link java.time.Duration#parse java.time.Duration&#125; compliant value * @since 3.2.2 */ String fixedDelayString() default \"\"; /** * Execute the annotated method with a fixed period in milliseconds between * invocations. * @return the period in milliseconds */ long fixedRate() default -1; /** * Execute the annotated method with a fixed period in milliseconds between * invocations. * @return the period in milliseconds as a String value, e.g. a placeholder * or a &#123;@link java.time.Duration#parse java.time.Duration&#125; compliant value * @since 3.2.2 */ String fixedRateString() default \"\"; /** * Number of milliseconds to delay before the first execution of a * &#123;@link #fixedRate()&#125; or &#123;@link #fixedDelay()&#125; task. * @return the initial delay in milliseconds * @since 3.2 */ long initialDelay() default -1; /** * Number of milliseconds to delay before the first execution of a * &#123;@link #fixedRate()&#125; or &#123;@link #fixedDelay()&#125; task. * @return the initial delay in milliseconds as a String value, e.g. a placeholder * or a &#123;@link java.time.Duration#parse java.time.Duration&#125; compliant value * @since 3.2.2 */ String initialDelayString() default \"\";&#125; 参数详解 cron该参数接收一个cron表达式，cron表达式是一个字符串，字符串以5或6个空格隔开，分开共6或7个域，每一个域代表一个含义。 cron表达式语法1[秒] [分] [小时] [日] [月] [周] [年] zone时区，接收一个java.util.TimeZone#ID。cron表达式会基于该时区解析。默认是一个空字符串，即取服务器所在地的时区。比如我们一般使用的时区Asia/Shanghai。该字段我们一般留空。 fixedDelay上一次执行完毕时间点之后多长时间再执行。如： 1@Scheduled(fixedDelay = 5000) //上一次执行完毕时间点之后5秒再执行 fixedDelayString与 3. fixedDelay 意思相同，只是使用字符串的形式。唯一不同的是支持占位符。如： 1@Scheduled(fixedDelayString = &quot;5000&quot;) //上一次执行完毕时间点之后5秒再执行 占位符的使用(配置文件中有配置：time.fixedDelay=5000)： 1234@Scheduled(fixedDelayString = &quot;$&#123;time.fixedDelay&#125;&quot;)void testFixedDelayString() &#123; System.out.println(&quot;Execute at &quot; + System.currentTimeMillis());&#125; fixedRate上一次开始执行时间点之后多长时间再执行。如： 1@Scheduled(fixedRate = 5000) //上一次开始执行时间点之后5秒再执行 fixedRateString与 5. fixedRate 意思相同，只是使用字符串的形式。唯一不同的是支持占位符。 initialDelay第一次延迟多长时间后再执行。如： 1@Scheduled(initialDelay=1000, fixedRate=5000) //第一次延迟1秒后执行，之后按fixedRate的规则每5秒执行一次 initialDelayString与 8. initialDelayString 意思相同，只是使用字符串的形式。唯一不同的是支持占位符。","categories":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/categories/spring/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"jetty","slug":"jetty","permalink":"http://yoursite.com/tags/jetty/"}]},{"title":"IDEA奇淫绝技","slug":"IDEA奇淫绝技","date":"2019-04-18T01:31:51.000Z","updated":"2019-04-18T02:15:49.136Z","comments":true,"path":"2019/04/18/IDEA奇淫绝技/","link":"","permalink":"http://yoursite.com/2019/04/18/IDEA奇淫绝技/","excerpt":"","text":"var声明 null判断 for遍历 取反 if条件判断 return返回","categories":[{"name":"idea","slug":"idea","permalink":"http://yoursite.com/categories/idea/"}],"tags":[{"name":"idea","slug":"idea","permalink":"http://yoursite.com/tags/idea/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-04-16T09:36:05.446Z","updated":"2019-04-17T09:15:07.268Z","comments":true,"path":"2019/04/16/hello-world/","link":"","permalink":"http://yoursite.com/2019/04/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 换电脑后同步一、安装必要软件 Git客户端 nodeJs 二、在github官网添加新电脑的密钥三、源文件拷贝将你原来电脑上个人博客目录下必要文件拷到你的新电脑上（比如F:/Blog目录下），注意无需拷全部，只拷如下几个目录：12345_config.yml package.json scaffolds/ source/ themes/ 四、安装hexo在cmd下输入指令安装hexonpm install hexo-cli -g 五、进入 F:/Blog 目录（你拷贝到新电脑的目录），输入下面指令安装相关模块12345npm installnpm install hexo-deployer-git --save // 文章部署到 git 的模块（下面为选择安装）npm install hexo-generator-feed --save // 建立 RSS 订阅npm install hexo-generator-sitemap --save // 建立站点地图 六、测试这时候使用 hexo s 基本可以看到你新添加的文章了。 七、部署发布文章123hexo clean // 清除缓存 网页正常情况下可以忽略此条命令hexo g // 生成静态网页hexo d // 开始部署 Github 添加 SSH Keys首先在本地创建 SSH Keys:1$ ssh-keygen -t rsa -C &quot;邮箱&quot; 后面的邮箱即为 github 注册邮箱，也是你登录 Github 的邮箱，之后会要求确认路径和输入密码，一路回车就行成功的话会在 ~/下生成 .ssh文件夹，进去，打开 id_rsa.pub，复制里面的key即可。测试下公钥有没有添加成功：ssh -T git@github.com","categories":[],"tags":[]},{"title":"MySQL高性能优化","slug":"MySQL高性能优化","date":"2019-02-22T01:33:40.000Z","updated":"2019-02-22T10:54:18.905Z","comments":true,"path":"2019/02/22/MySQL高性能优化/","link":"","permalink":"http://yoursite.com/2019/02/22/MySQL高性能优化/","excerpt":"","text":"前言在进行MySQL的优化之前必须要了解的就是MySQL的查询过程，很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。 优化的哲学优化有风险，涉足需谨慎 优化可能带来的问题 优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统。 优化手段本来就有很大的风险，只不过你没能力意识到和预见到！ 任何的技术可以解决一个问题，但必然存在带来一个问题的风险！ 对于优化来说解决问题而带来的问题,控制在可接受的范围内才是有成果。 保持现状或出现更差的情况都是失败！ 优化的需求 稳定性和业务可持续性,通常比性能更重要！ 优化不可避免涉及到变更，变更就有风险！ 优化使性能变好，维持和变差是等概率事件！ 切记优化,应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化！ 所以优化工作,是由业务需要驱使的！！！ 优化思路优化什么 在数据库优化上有两个主要方面：即安全与性能。 安全 —&gt; 数据可持续性 性能 —&gt; 数据的高性能访问 优化的范围有哪些存储、主机和操作系统方面: 主机架构稳定性 I/O规划及配置 Swap交换分区 OS内核参数和网络问题 应用程序方面: 应用程序稳定性 SQL语句性能 串行访问资源 性能欠佳会话管理 这个应用适不适合用MySQL 数据库优化方面: 内存 数据库结构(物理&amp;逻辑) 实例配置 说明：不管是在，设计系统，定位问题还是优化，都可以按照这个顺序执行。 优化纬度数据库优化维度有四个: 硬件、系统配置、数据库表结构、SQL及索引 优化选择 优化成本:硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引 优化效果:硬件&lt;系统配置&lt;数据库表结构 优化工具数据库层面123456789101112mysqlmsyqladmin mysql客户端，可进行管理操作mysqlshow 功能强大的查看shell命令show [SESSION | GLOBAL] variables 查看数据库参数信息SHOW [SESSION | GLOBAL] STATUS 查看数据库的状态信息information_schema 获取元数据的方法SHOW ENGINE INNODB STATUS Innodb引擎的所有状态SHOW PROCESSLIST 查看当前所有连接session状态explain 获取查询语句的执行计划show index 查看表的索引信息slow-log 记录慢查询语句mysqldumpslow 分析slowlog文件的 检查问题常用工具 1234567zabbix 监控主机、系统、数据库（部署zabbix监控平台）pt-query-digest 分析慢日志mysqlslap 分析慢日志sysbench 压力测试工具mysql profiling 统计数据库整体状态工具 Performance Schema mysql性能状态统计的数据workbench 管理、备份、监控、分析、优化工具（比较费资源） 关于zabbix参考：http://www.cnblogs.com/clsn/p/7885990.html 数据库层面问题解决思路一般应急调优的思路： 针对突然的业务办理卡顿，无法进行正常的业务处理！需要立马解决的场景！ 1、show processlist 2、explain select id ,name from stu where name=’clsn’; # ALL id name age sex select id,name from stu where id=2-1 函数 结果集&gt;30; show index from table; 3、通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题 4、show status like ‘%lock%’; # 查询锁状态 kill SESSION_ID; # 杀掉有问题的session 常规调优思路： 针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。 1、查看slowlog，分析slowlog，分析出查询慢的语句。 2、按照一定优先级，进行一个一个的排查所有慢语句。 3、分析top sql，进行explain调试，查看语句执行时间。 4、调整索引或语句本身。 系统层面cpu方面 1vmstat、sar top、htop、nmon、mpstat 内存 1free 、ps -aux 、 IO设备（磁盘、网络） 1iostat 、 ss 、 netstat 、 iptraf、iftop、lsof、 vmstat 命令说明： 123456Procs：r显示有多少进程正在等待CPU时间。b显示处于不可中断的休眠的进程数量。在等待I/OMemory：swpd显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1和s0最好是0Io：每秒从设备中读入b1的写入到设备b0的数据块的数量。反映了磁盘I/OSystem：显示了每秒发生中断的数量(in)和上下文交换(cs)的数量Cpu：显示用于运行用户代码，系统代码，空闲，等待I/O的CPU时间 iostat**命令说明** 123456789实例命令： iostat -dk 1 5 iostat -d -k -x 5 （查看设备使用率（%util）和响应时间（await））tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。iops ：硬件出厂的时候，厂家定义的一个每秒最大的IO次数&quot;一次传输&quot;请求的大小是未知的。kB_read/s：每秒从设备（drive expressed）读取的数据量；KB_wrtn/s：每秒向设备（drive expressed）写入的数据量；kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 系统层面问题解决办法你认为到底负载高好，还是低好呢？ 在实际的生产中，一般认为 cpu只要不超过90%都没什么问题 。 当然不排除下面这些特殊情况： 问题一：cpu负载高，IO负载低 内存不够 磁盘性能差 SQL问题 ——&gt;去数据库层，进一步排查sql问题 IO出问题了（磁盘到临界了、raid设计不好、raid降级、锁、在单位时间内tps过高） tps过高: 大量的小数据IO、大量的全表扫描 问题二：IO负载高，cpu负载低 大量小的IO 写操作： autocommit ，产生大量小IO IO/PS,磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的IO次数。 大量大的IO 写操作 SQL问题的几率比较大 问题三：IO和cpu负载都很高 硬件不够了或sql存在问题 基础优化优化思路定位问题点吮吸 硬件 –&gt; 系统 –&gt; 应用 –&gt; 数据库 –&gt; 架构（高可用、读写分离、分库分表） 处理方向 明确优化目标、性能和安全的折中、防患未然 硬件优化主机方面： 根据数据库类型，主机CPU选择、内存容量选择、磁盘选择 平衡内存和磁盘资源 随机的I/O和顺序的I/O 主机 RAID卡的BBU(Battery Backup Unit)关闭 cpu的选择： cpu的两个关键因素：核数、主频 根据不同的业务类型进行选择： cpu密集型：计算比较多，OLTP 主频很高的cpu、核数还要多 IO密集型：查询比较，OLAP 核数要多，主频不一定高的 内存的选择： OLAP类型数据库，需要更多内存，和数据获取量级有关。 OLTP类型数据一般内存是cpu核心数量的2倍到4倍，没有最佳实践。 存储方面： 根据存储数据种类的不同，选择不同的存储设备 配置合理的RAID级别(raid5、raid10、热备盘) 对与操作系统来讲，不需要太特殊的选择，最好做好冗余（raid1）（ssd、sas 、sata） raid卡：主机raid卡选择： 实现操作系统磁盘的冗余（raid1） 平衡内存和磁盘资源 随机的I/O和顺序的I/O 主机 RAID卡的BBU(Battery Backup Unit)要关闭。 网络设备方面： 使用流量支持更高的网络设备（交换机、路由器、网线、网卡、HBA卡） 注意：以上这些规划应该在初始设计系统时就应该考虑好。 服务器硬件优化 1、物理状态灯： 2、自带管理设备：远程控制卡（FENCE设备：ipmi ilo idarc），开关机、硬件监控。 3、第三方的监控软件、设备（snmp、agent）对物理设施进行监控 4、存储设备：自带的监控平台。EMC2（hp收购了）， 日立（hds），IBM低端OEM hds，高端存储是自己技术，华为存储 系统优化Cpu： 基本不需要调整，在硬件选择方面下功夫即可。 内存： 基本不需要调整，在硬件选择方面下功夫即可。 SWAP： MySQL尽量避免使用swap。 阿里云的服务器中默认swap为0 IO ： raid、no lvm、 ext4或xfs、ssd、IO调度策略 Swap调整(不使用swap分区) 1/proc/sys/vm/swappiness的内容改成0（临时），/etc/sysctl.conf上添加vm.swappiness=0（永久） 这个参数决定了Linux是倾向于使用swap，还是倾向于释放文件系统cache。在内存紧张的情况下，数值越低越倾向于释放文件系统cache。 当然，这个参数只能减少使用swap的概率，并不能避免Linux使用swap。 修改MySQL的配置参数innodb_flush_method，开启O_DIRECT**模式。** 这种情况下，InnoDB的buffer pool会直接绕过文件系统cache来访问磁盘，但是redo log依旧会使用文件系统cache。 值得注意的是，Redo log是覆写模式的，即使使用了文件系统的cache，也不会占用太多 IO**调度策略** 1#echo deadline&gt;/sys/block/sda/queue/scheduler 临时修改为deadline 永久修改 123vi /boot/grub/grub.conf更改到如下内容:kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet 系统参数调整Linux系统内核参数优化 12345vim /etc/sysctl.conf net.ipv4.ip_local_port_range = 1024 65535 # 用户端口范围 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_fin_timeout = 30 fs.file-max=65535 # 系统最大文件句柄，控制的是能打开文件最大数量 用户限制参数（mysql可以不设置以下配置） 12345vim /etc/security/limits.conf * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535 应用优化 业务应用和数据库应用独立, 防火墙：iptables、selinux等其他无用服务(关闭)： 123456789101112131415chkconfig --level 23456 acpid offchkconfig --level 23456 anacron offchkconfig --level 23456 autofs offchkconfig --level 23456 avahi-daemon offchkconfig --level 23456 bluetooth offchkconfig --level 23456 cups offchkconfig --level 23456 firstboot offchkconfig --level 23456 haldaemon offchkconfig --level 23456 hplip offchkconfig --level 23456 ip6tables offchkconfig --level 23456 iptables offchkconfig --level 23456 isdn offchkconfig --level 23456 pcscd offchkconfig --level 23456 sendmail offchkconfig --level 23456 yum-updatesd off 安装图形界面的服务器不要启动图形界面 runlevel 3 另外，思考将来我们的业务是否真的需要MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。 数据库优化SQL优化方向： 执行计划、索引、SQL改写 架构优化方向： 高可用架构、高性能架构、分库分表 数据库参数优化调整： 实例整体（高级优化，扩展）： 123456thread_concurrency # 并发线程数量个数sort_buffer_size # 排序缓存read_buffer_size # 顺序读取缓存read_rnd_buffer_size # 随机读取缓存key_buffer_size # 索引缓存thread_cache_size # (1G—&gt;8, 2G—&gt;16, 3G—&gt;32, &gt;3G—&gt;64) 连接层（基础优化） 设置合理的连接客户和连接方式 1234567max_connections # 最大连接数，看交易笔数设置 max_connect_errors # 最大错误连接数，能大则大connect_timeout # 连接超时max_user_connections # 最大用户连接数skip-name-resolve # 跳过域名解析wait_timeout # 等待超时back_log # 可以在堆栈中的连接数量 SQL层（基础优化） 1234query_cache_size： 查询缓存 &gt;&gt;&gt; OLAP类型数据库,需要重点加大此内存缓存， 但是一般不会超过GB 对于经常被修改的数据，缓存会立马失效。 我们可以实用内存数据库（redis、memecache），替代他的功能。 存储引擎层（innodb基础优化参数）1234567891011121314default-storage-engineinnodb_buffer_pool_size # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70%innodb_file_per_table=(1,0)innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中binlog_syncInnodb_flush_method=(O_DIRECT, fdatasync)innodb_log_buffer_size # 100M以下innodb_log_file_size # 100M 以下innodb_log_files_in_group # 5个成员以下,一般2-3个够用（iblogfile0-N）innodb_max_dirty_pages_pct # 达到百分之75的时候刷写 内存脏页到磁盘。log_binmax_binlog_cache_size # 可以不设置max_binlog_size # 可以不设置innodb_additional_mem_pool_size #小于2G内存的机器，推荐值是20M。32G内存以上100M","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"cron表达式","slug":"cron表达式","date":"2019-02-18T02:53:24.000Z","updated":"2019-02-18T08:25:00.033Z","comments":true,"path":"2019/02/18/cron表达式/","link":"","permalink":"http://yoursite.com/2019/02/18/cron表达式/","excerpt":"","text":"quartz定时任务cron表达式详解cron表达式用于配置cronTrigger的实例。cron表达式实际上是由七个子表达式组成。这些表达式之间用空格分隔。 Seconds （秒） Minutes（分） Hours（小时） Day-of-Month （天） Month（月） Day-of-Week （周） Year（年） 例：”0 0 12 ? * WED” 意思是：每个星期三的中午12点执行。 个别子表达式可以包含范围或者列表。例如：上面例子中的WED可以换成”MON-FRI”，”MON,WED,FRI”，甚至”MON-WED,SAT”。 子表达式范围 Seconds (0~59) Minutes (0~59) Hours (0~23) Day-of-Month (1~31,但是要注意有些月份没有31天) Month (0~11，或者”JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV,DEC”) Day-of-Week (1~7,1=SUN 或者”SUN, MON, TUE, WED, THU, FRI, SAT”) Year (1970~2099) Cron表达式的格式：秒 分 时 日 月 周 年(可选)。字段名 允许的值 允许的特殊字符秒 0-59 , - /分 0-59 , - /小时 0-23 , - /日 1-31 , - ? / L W C月 1-12 or JAN-DEC , - /周几 1-7 or SUN-SAT , - ? / L C #年(可选字段) empty 1970-2099 , - * / 字符含义 * ：代表所有可能的值。因此，“*”在Month中表示每个月，在Day-of-Month中表示每天，在Hours表示每小时 - ：表示指定范围。 , ：表示列出枚举值。例如：在Minutes子表达式中，“5,20”表示在5分钟和20分钟触发。 / ：被用于指定增量。例如：在Minutes子表达式中，“0/15”表示从0分钟开始，每15分钟执行一次。”3/20”表示从第三分钟开始，每20分钟执行一次。和”3,23,43”（表示第3，23，43分钟触发）的含义一样。 ? ：用在Day-of-Month和Day-of-Week中，指“没有具体的值”。当两个子表达式其中一个被指定了值以后，为了避免冲突，需要将另外一个的值设为“?”。例如：想在每月20日触发调度，不管20号是星期几，只能用如下写法：0 0 0 20 ?，其中最后以为只能用“?”，而不能用“”。 L ：用在day-of-month和day-of-week字串中。它是单词“last”的缩写。它在两个子表达式中的含义是不同的。在day-of-month中，“L”表示一个月的最后一天，一月31号，3月30号。在day-of-week中，“L”表示一个星期的最后一天，也就是“7”或者“SAT”如果“L”前有具体内容，它就有其他的含义了。例如：“6L”表示这个月的倒数第六天。“FRIL”表示这个月的最后一个星期五。注意：在使用“L”参数时，不要指定列表或者范围，这样会出现问题。 W ：“Weekday”的缩写。只能用在day-of-month字段。用来描叙最接近指定天的工作日（周一到周五）。例如：在day-of-month字段用“15W”指“最接近这个月第15天的工作日”，即如果这个月第15天是周六，那么触发器将会在这个月第14天即周五触发；如果这个月第15天是周日，那么触发器将会在这个月第 16天即周一触发；如果这个月第15天是周二，那么就在触发器这天触发。注意一点：这个用法只会在当前月计算值，不会越过当前月。“W”字符仅能在 day-of-month指明一天，不能是一个范围或列表。也可以用“LW”来指定这个月的最后一个工作日，即最后一个星期五。 # ：只能用在day-of-week字段。用来指定这个月的第几个周几。例：在day-of-week字段用”6#3” or “FRI#3”指这个月第3个周五（6指周五，3指第3个）。如果指定的日期不存在，触发器就不会触发。 示例0 * * * * ? 每1分钟触发一次0 0 * * * ? 每天每1小时触发一次0 0 10 * * ? 每天10点触发一次0 * 14 * * ?在每天下午2点到下午2:59期间的每1分钟触发0 30 9 1 * ? 每月1号上午9点半0 15 10 15 * ? 每月15日上午10:15触发 */5 * * * * ? 每隔5秒执行一次0 */1 * * * ? 每隔1分钟执行一次0 0 5-15 * * ? 每天5-15点整点触发0 0/3 * * * ? 每三分钟触发一次0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发0 0/5 14 * * ? 在每天下午2点到下午2:55期间的每5分钟触发0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时0 0 10,14,16 * * ? 每天上午10点，下午2点，4点 0 0 12 ? * WED 表示每个星期三中午12点0 0 17 ? * TUES,THUR,SAT 每周二、四、六下午五点0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发0 15 10 ? * MON-FRI 周一至周五的上午10:15触发 0 0 23 L * ? 每月最后一天23点执行一次0 15 10 L * ? 每月最后一日的上午10:15触发0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发 0 15 10 * * ? 2005 2005年的每天上午10:15触发0 15 10 ? * 6L 2002-2005 2002年至2005年的每月的最后一个星期五上午10:15触发0 15 10 ? * 6#3 每月的第三个星期五上午10:15触发","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"cron","slug":"cron","permalink":"http://yoursite.com/tags/cron/"}]},{"title":"Mysql学习记录","slug":"MySql学习记录","date":"2019-02-12T01:33:40.000Z","updated":"2019-02-18T08:05:07.951Z","comments":true,"path":"2019/02/12/MySql学习记录/","link":"","permalink":"http://yoursite.com/2019/02/12/MySql学习记录/","excerpt":"","text":"目标MySql短短续续的学习，过一段时间就忘了，本篇文章用来记录学习MySql的点点滴滴，一方面做一个笔记，加深学习的印象，另一方面也是对自身总结能力的提升，此次学习的参考主要是极客时间的《MySql实战》 基础架构：一条SQL查询语句是如何执行的？先来看一张图： MySQL可以分为Server层和存储引擎层 Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持MyISAM、InnoDB、Memory等多个引擎 不同的存储引擎共用一个Server层 连接器 负责客户端建立连接、获取权限、维持和管理链接 mysql -h$ip -P$port -u$user -p 另外，权限的修改只会在后面的新连接生效 查询缓存 顾名思义，先查询缓存，缓存中以key-value形式存在，key是查询语句，value是查询的结果。 不过，大多数情况下不建议使用查询缓存，弊大于利 分析器 对SQL语句分析，先做“词法分析”，再做“语法分析” 词法分析分析这条语句是条什么语句 语法分析分析这条语句是否满足MySQL语法 优化器 优化器是在表里面有多个索引的时候，决定使用哪个索引； 或者在一个语句有多表关联jion的时候，决定各个表的链接顺序等等的优化 执行器 日志系统：一条SQL更新语句是如何执行的？WAL技术Write-Ahead Logging，先写日志，再写磁盘。 具体来说，当有一条记录需要更新的时候，InnoDB引擎会先把记录写到redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候。 InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作，从头开始，写到末尾就又回到开头循环写。 有了redo log，Inno就可以保证即使数据库发生异常重启后，之前提交的记录都不会丢失，这个能力成为crash-safe binlogredo log是InnoDB引擎特有的日志，而Server层也有自己的日志，成为binlog redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用的 redo log是物理日志，记录的是“某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1” redo log是循环写的，空间固定会用完；binlog是可以追加的。 为什么表数据删掉一半，表文件大小不变innodb_file_per_table OFF 表的数据放在系统共享表空间，也就是跟数据字典放在一起 ON 每个InnoDB表数据存储在一个以.ibd为后缀的文件中 从MySQL 5.6.6版本开始，默认值就是ON了 数据删除流程 删除R4这个记录，InnoDB引擎只会把R4这个记录标记为删除，如果之后要在插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。 InnoDB的数据是按页存储的，那么如果我们删掉一个数据页上的所有就录，那么整个数据页就可以被复用了。 delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的，也就是说，通过delete命令是不能回收表空间的，这些可以复用，而没有被使用的空间，看起来就像是“空洞” 不只是删除数据会造成空洞，插入数据也会 重建表alter table A engine=InnoDB 重建表 如果在这个过程中，有新的数据要写入到A的话，就会造成数据丢失。因此。在整个DDL过程中，表A中不能有更新，即这个DDL不是Online的 Online DDL count(*)这么慢，我该怎么办？count(*)的实现方式 MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高 InnoDB就麻烦了，执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累计计数 如果加where的话MyISAM也不可能返回这么快 MyISAM表虽然coung(*)很快，但是不支持事务 show table status 命令虽然返回很快，但是不准确 InnoDB表直接count(*)会遍历全表，虽然结果准备，但会导致性能问题 不同count 的用法几个原则 server层要什么就给什么 InnoDB只会给必要的值 现在优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做 count(主键id),InnoDB会遍历正好在那个表，把每一行的id值都取出来，返回给server层，server层拿到id后，判断是不可能为空的，就按行累加 count(1)InnoDB遍历整张表，但不取值，server层对于返回的每一个行，放一个数字1进去，判断是不可能为空的就按行累加 count(1)执行要比count(id)快，因为引擎返回id会涉及到解析数据行，以及拷贝字段值的操作 count(字段) 这个字段为not null 的话，一行行从记录里独处这个字段，判断不能为nulll，按行累加 允许为null，要先取值，不是null，累加 count(*)是个例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加 结论：按照效率排序的话,count(字段)&lt;count(id)&lt;count(1)~count(*) order by 是怎么工作的123456789CREATE TABLE `t` ( `id` int(11) NOT NULL, `city` varchar(16) NOT NULL, `name` varchar(16) NOT NULL, `age` int(11) NOT NULL, `addr` varchar(128) DEFAULT NULL, PRIMARY KEY (`id`), KEY `city` (`city`)) ENGINE=InnoDB; select city,name,age from t where city=&#39;杭州&#39; order by name limit 1000 ; 全字段排序在city字段上创建索引之后，用explain命令 Using filesort表示需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer rowid排序MySQL认为排序的单行长度太大会怎么做？ SET max_length_for_sort_data = 16; max_length_for_sort_data。是MySQL中专门控制用于排序的行数据的长度的一个参数，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法 新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id MySQL是怎么保证主备一致的？MySQL 是以容易学习和方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖于 binlog。虽然这些高可用架构已经呈现出越来越复杂的趋势，但都是从最基本的一主一备演化过来的。 主备的基本原理 在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑： 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作； 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致； 可以用 readonly 状态，来判断节点的角色。 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。 节点 A 到 B 这条线的内部流程是什么样的。 一个事务日志同步的完整过程是这样的： 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread和 sql_thread。其中 io_thread 负责与主库建立连接。 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。 sql_thread 读取中转日志，解析出日志里的命令，并执行。 binlog的三种格式 statement 记录到 binlog 里的是语句原文 row 需要借助 mysqlbinlog 工具 mysqlbinlog -vv data/master.000001 --start-position=8900; binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。 mixed 为什么会有 mixed 这种 binlog 格式的存在场景？ 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。 现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。 这么做的理由有很多，一个可以直接看出来的好处：恢复数据 循环复制问题解决两个节点间的循环复制的问题： 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系； 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的binlog； 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。 MySQL是怎么保证高可用的？主备延迟 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1; 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2; 备库 B 执行完成这个事务，我们把这个时刻记为 T3。 所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。 执行 show slave status 命令,它的返回结果里面会显示seconds_behind_master，用于表示当前备库延迟了多少秒。 seconds_behind_master 的计算方法是这样的： 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间； 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到seconds_behind_master。 主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产binlog 的速度要慢。 主备延迟的来源 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。 备库的压力大 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。 大事务 不要一次性地用 delete 语句删除太多数据 备库的并行复制能力 可靠性优先策略可用性优先策略备库为什么会延迟好几个小时？ coordinator 在分发的时候，需要满足以下这两个基本要求： 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker中。 同一个事务不能被拆开，必须放到同一个 worker 中。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"【转】缓存架构优化","slug":"缓存架构优化","date":"2019-01-18T07:33:23.000Z","updated":"2019-04-17T01:26:54.725Z","comments":true,"path":"2019/01/18/缓存架构优化/","link":"","permalink":"http://yoursite.com/2019/01/18/缓存架构优化/","excerpt":"","text":"缓存集群两大问题 热key 缓存集群中的某个key瞬间被数万甚至十万的并发请求打爆。 大value 你的某个key对应的value可能有GB级的大小，导致查询value的时候导致网络相关的故障问题。 这篇文章，我们就来聊聊热key问题。先来看看下面的一幅图。 简单来说，假设你手头有个系统，他本身是集群部署的，然后后面有一套缓存集群，这个集群不管你用redis cluster，还是memcached，或者是公司自研缓存集群，都可以。 那么，这套系统用缓存集群干什么呢？ 很简单了，在缓存里放一些平时不怎么变动的数据，然后用户在查询大量的平时不怎么变动的数据的时候，不就可以直接从缓存里走了吗？ 缓存集群的并发能力是很强的，而且读缓存的性能是很高的。 举个例子，假设你每秒有2万请求，但是其中90%都是读请求，那么每秒1.8万请求都是在读一些不太变化的数据，而不是写数据。 那此时你把数据都放在数据库里，然后每秒发送2万请求到数据库上读写数据，你觉得合适吗？ 当然不太合适了，如果你要用数据库承载每秒2万请求的话，那么不好意思，你很可能就得搞分库分表 + 读写分离。 比如你得分3个主库，承载每秒2000的写入请求，然后每个主库挂3个从库，一共9个从库承载每秒1.8万的读请求。 这样的话，你可能就需要一共是12台高配置的数据库服务器，这是很耗费钱的，成本非常高，而且很不合适。 大家看看下面的图，来体会下这种情况。 所以，此时你完全就可以把平时不太变化的数据放在缓存集群里，缓存集群可以采用2主2从，主节点用来写入缓存，从节点用来读缓存。 以缓存集群的性能，2个从节点完全可以用来承载每秒1.8万的大量读了，然后3个数据库主库就是承载每秒2000的写请求和少量其他读请求就可以了。 大家看看下面的图，你耗费的机器瞬间变成了4台缓存机器 + 3台数据库机器 = 7台机器，是不是比之前的12台机器减少了很大的资源开销？ 没错，缓存其实在系统架构里是非常重要的组成部分。很多时候，对于那些很少变化但是大量高并发读的数据，通过缓存集群来抗高并发读，是非常合适的。 这里所有的机器数量、并发请求量都是一个示例，大家主要是体会一下这个意思就好，其目的主要是给一些不太熟悉缓存相关技术的同学一点背景性的阐述，让这些同学能够理解在系统里用缓存集群承载读请求是什么意思。 （2）20万用户同时访问一个热点缓存的问题好了，背景是已经给大家解释清楚了，那么现在就可以给大家说说今天重点要讨论的问题：热点缓存。 我们来做一个假设，你现在有10个缓存节点来抗大量的读请求。正常情况下，读请求应该是均匀的落在10个缓存节点上的，对吧！ 这10个缓存节点，每秒承载1万请求是差不多的。 然后我们再做一个假设，你一个节点承载2万请求是极限，所以一般你就限制一个节点正常承载1万请求就ok了，稍微留一点buffer出来。 好，所谓的热点缓存问题是什么意思呢？ 很简单，就是突然因为莫名的原因，出现大量的用户访问同一条缓存数据。 举个例子，某个明星突然宣布跟某某结婚，这个时候是不是会引发可能短时间内每秒都是数十万的用户去查看这个明星跟某某结婚的那条新闻？ 那么假设那条新闻就是一个缓存，然后对应就是一个缓存key，就存在一台缓存机器上，此时瞬时假设有20万请求奔向那一台机器上的一个key。 此时会如何？我们看看下面的图，来体会一下这种绝望的感受。 这个时候很明显了，我们刚才假设的是一个缓存Slave节点最多每秒就是2万的请求，当然实际缓存单机承载5万~10万读请求也是可能的，我们这里就是一个假设。 结果此时，每秒突然奔过来20万请求到这台机器上，会怎么样？ 很简单，上面图里那台被20万请求指向的缓存机器会过度操劳而宕机的。 那么如果缓存集群开始出现机器的宕机，此时会如何？ 接着，读请求发现读不到数据，会从数据库里提取原始数据，然后放入剩余的其他缓存机器里去。但是接踵而来的每秒20万请求，会再次压垮其他的缓存机器。 以此类推，最终导致缓存集群全盘崩溃，引发系统整体宕机。 咱们看看下面的图，再感受一下这个恐怖的现场。 （3）基于流式计算技术的缓存热点自动发现其实这里关键的一点，就是对于这种热点缓存，你的系统需要能够在热点缓存突然发生的时候，直接发现他，然后瞬间立马实现毫秒级的自动负载均衡。 那么我们就先来说说，你如何自动发现热点缓存问题？ 首先你要知道，一般出现缓存热点的时候，你的每秒并发肯定是很高的，可能每秒都几十万甚至上百万的请求量过来，这都是有可能的。 所以，此时完全可以基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如storm、spark streaming、flink，这些技术都是可以的。 然后一旦在实时数据访问次数统计的过程中，比如发现一秒之内，某条数据突然访问次数超过了1000，就直接立马把这条数据判定为是热点数据，可以将这个发现出来的热点数据写入比如zookeeper中。 当然，你的系统如何判定热点数据，可以根据自己的业务还有经验值来就可以了。 大家看看下面这张图，看看整个流程是如何进行的。 当然肯定有人会问，那你的流式计算系统在进行数据访问次数统计的时候，会不会也存在说单台机器被请求每秒几十万次的问题呢？ 答案是否，因为流式计算技术，尤其是storm这种系统，他可以做到同一条数据的请求过来，先分散在很多机器里进行本地计算，最后再汇总局部计算结果到一台机器进行全局汇总。 所以几十万请求可以先分散在比如100台机器上，每台机器统计了这条数据的几千次请求。 然后100条局部计算好的结果汇总到一台机器做全局计算即可，所以基于流式计算技术来进行统计是不会有热点问题的。 （4）热点缓存自动加载为JVM本地缓存我们自己的系统可以对zookeeper指定的热点缓存对应的znode进行监听，如果有变化他立马就可以感知到了。 此时系统层就可以立马把相关的缓存数据从数据库加载出来，然后直接放在自己系统内部的本地缓存里即可。 这个本地缓存，你用ehcache、hashmap，其实都可以，一切都看自己的业务需求，主要说的就是将缓存集群里的集中式缓存，直接变成每个系统自己本地实现缓存即可，每个系统自己本地是无法缓存过多数据的。 因为一般这种普通系统单实例部署机器可能就一个4核8G的机器，留给本地缓存的空间是很少的，所以用来放这种热点数据的本地缓存是最合适的，刚刚好。 假设你的系统层集群部署了100台机器，那么好了，此时你100台机器瞬间在本地都会有一份热点缓存的副本。 然后接下来对热点缓存的读操作，直接系统本地缓存读出来就给返回了，不用再走缓存集群了。 这样的话，也不可能允许每秒20万的读请求到达缓存机器的一台机器上读一个热点缓存了，而是变成100台机器每台机器承载数千请求，那么那数千请求就直接从机器本地缓存返回数据了，这是没有问题的。 我们再来画一幅图，一起来看看这个过程： （5）限流熔断保护除此之外，在每个系统内部，其实还应该专门加一个对热点数据访问的限流熔断保护措施。 每个系统实例内部，都可以加一个熔断保护机制，假设缓存集群最多每秒承载4万读请求，那么你一共有100个系统实例。 你自己就该限制好，每个系统实例每秒最多请求缓存集群读操作不超过400次，一超过就可以熔断掉，不让请求缓存集群，直接返回一个空白信息，然后用户稍后会自行再次重新刷新页面之类的。 通过系统层自己直接加限流熔断保护措施，可以很好的保护后面的缓存集群、数据库集群之类的不要被打死，我们来看看下面的图。 （6）本文总结具体要不要在系统里实现这种复杂的缓存热点优化架构呢？这个还要看你们自己的系统有没有这种场景了。 如果你的系统有热点缓存问题，那么就要实现类似本文的复杂热点缓存支撑架构。 但是如果没有的话，那么也别过度设计，其实你的系统可能根本不需要这么复杂的架构。 如果是后者，那么大伙儿就权当看看本文，来了解一下对应的架构思想好了^_^ 原文链接： 如果20万用户同时访问一个热点缓存，如何优化你的缓存架构？","categories":[{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/categories/缓存/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"http://yoursite.com/tags/缓存/"},{"name":"优化","slug":"优化","permalink":"http://yoursite.com/tags/优化/"}]},{"title":"RabbitMQ的confirm机制","slug":"RabbitMQ的confirm机制","date":"2019-01-17T00:59:10.000Z","updated":"2019-01-17T01:37:43.297Z","comments":true,"path":"2019/01/17/RabbitMQ的confirm机制/","link":"","permalink":"http://yoursite.com/2019/01/17/RabbitMQ的confirm机制/","excerpt":"","text":"confirm机制生产端（比如上图的订单服务）首先需要开启一个confirm模式，接着投递到MQ的消息，如果MQ一旦将消息持久化到磁盘之后，必须也要回传一个confirm消息给生产端。 这样的话，如果生产端的服务接收到了这个confirm消息，就知道是已经持久化到磁盘了。 否则如果没有接收到confirm消息，那么就说明这条消息半路可能丢失了，此时你就可以重新投递消息到MQ去，确保消息不要丢失。 而且一旦你开启了confirm模式之后，每次消息投递也同样是有一个delivery tag的，也是起到唯一标识一次消息投递的作用。 这样，MQ回传ack给生产端的时候，会带上这个delivery tag。你就知道具体对应着哪一次消息投递了，可以删除这条消息。 此外，如果RabbitMQ接收到一条消息之后，结果内部出错发现无法处理这条消息，那么他会回传一个nack消息给生产端。此时你就会感知到这条消息可能处理有问题，你可以选择重新再次投递这条消息到MQ去。 或者另一种情况，如果某条消息很长时间都没给你回传ack/nack，那可能是极端意外情况发生了，数据也丢了，你也可以自己重新投递消息到MQ去。 通过这套confirm机制，就可以实现生产端投递消息不会丢失的效果。 confirm代码实现123456789101112131415161718channel.confirmSelect(); //将channel设置为confirm模式channel.addconfirmListener(new ConfirmListener()&#123; //回调方法，专门处理MQ回传的ack //收到这个ack消息，说明发送的消息被MQ给confirm了，持久化到磁盘 public void handleAck(long deliverTag, boolaen multipe) throws IOException&#123; //可以把发送出去的，但是还没被ack的消息，先保存在内存/数据量/缓存/kx存储 //然后收到这个消息的ack之后，就可以删除对应的消息了 //deliverTag就是唯一标识了一个消息投递 &#125; public void handleNack(long deliveryTag, boolean multipe) throws IOException&#123; //在这里，如果收到消息的nack通知，那么可以选择重新投递消息 //当然，为了避免其他的一些意外，也可以自己轮询遍历所有未ack的消息 //达到一定的超时时间之后，自己主动重新投递消息也是可以的 &#125;&#125;) confirm的高延迟性这里有一个很关键的点，就是一旦启用了confirm机制投递消息到MQ之后，MQ是不保证什么时候会给你一个ack或者nack的。 因为RabbitMQ自己内部将消息持久化到磁盘，本身就是通过异步批量的方式来进行的。 正常情况下，你投递到RabbitMQ的消息都会先驻留在内存里，然后过了几百毫秒的延迟时间之后，再一次性批量把多条消息持久化到磁盘里去。 这样做，是为了兼顾高并发写入的吞吐量和性能的，因为要是你来一条消息就写一次磁盘，那么性能会很差，每次写磁盘都是一次fsync强制刷入磁盘的操作，是很耗时的。 所以正是因为这个原因，你打开了confirm模式之后，很可能你投递出去一条消息，要间隔几百毫秒之后，MQ才会把消息写入磁盘，接着你才会收到MQ回传过来的ack消息，这个就是所谓confirm机制投递消息的高延迟性 高并发下的设置在生产端高并发写入MQ的场景下，你会面临两个问题： 1、你每次写一条消息到MQ，为了等待这条消息的ack，必须把消息保存到一个存储里。 并且这个存储不建议是内存，因为高并发下消息是很多的，每秒可能都几千甚至上万的消息投递出去，消息的ack要等几百毫秒的话，放内存可能有内存溢出的风险。 2、绝对不能以同步写消息 + 等待ack的方式来投递，那样会导致每次投递一个消息都同步阻塞等待几百毫秒，会导致投递性能和吞吐量大幅度下降。 针对这两个问题，相对应的方案其实也呼之欲出了。 首先，用来临时存放未ack消息的存储需要承载高并发写入，而且我们不需要什么复杂的运算操作，这种存储首选绝对不是MySQL之类的数据库，而建议采用kv存储。kv存储承载高并发能力极强，而且kv操作性能很高。 其次，投递消息之后等待ack的过程必须是异步的，也就是类似上面那样的代码，已经给出了一个初步的异步回调的方式。 消息投递出去之后，这个投递的线程其实就可以返回了，至于每个消息的异步回调，是通过在channel注册一个confirm监听器实现的。 收到一个消息ack之后，就从kv存储中删除这条临时消息；收到一个消息nack之后，就从kv存储提取这条消息然后重新投递一次即可；也可以自己对kv存储里的消息做监控，如果超过一定时长没收到ack，就主动重发消息。","categories":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/tags/MQ/"}]},{"title":"高并发降级方案","slug":"降级方案","date":"2019-01-16T07:27:23.000Z","updated":"2019-01-16T06:36:52.900Z","comments":true,"path":"2019/01/16/降级方案/","link":"","permalink":"http://yoursite.com/2019/01/16/降级方案/","excerpt":"","text":"介绍在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。 当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。 降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。 降级按照是否自动化可分为：自动开关降级和人工开关降级。 降级按照功能可分为：读服务降级、写服务降级。 降级按照处于的系统层次可分为：多级降级。 读写双缓存降级方案","categories":[{"name":"架构","slug":"架构","permalink":"http://yoursite.com/categories/架构/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"http://yoursite.com/tags/高并发/"},{"name":"降级","slug":"降级","permalink":"http://yoursite.com/tags/降级/"}]},{"title":"消息中间件","slug":"消息中间件","date":"2019-01-16T01:53:36.000Z","updated":"2019-01-17T02:11:09.878Z","comments":true,"path":"2019/01/16/消息中间件/","link":"","permalink":"http://yoursite.com/2019/01/16/消息中间件/","excerpt":"","text":"消息中间件选型 ActiveMQ 没法确认ActiveMQ可以支撑互联网公司的高并发、高负载以及高吞吐的复杂场景，在国内互联网公司落地较少，而且使用较多的是一些传统企业，用ActiveMQ做异步调用和系统解耦 RabbitMQ 支撑高并发、高吞吐、性能很高，同时有非常完善便捷的后台管理界面，另外，支持集群化、高可用部署架构、消息高可靠支持、功能较为完善。 而且经过调研，国内各大互联网公司落地大规模RabbitMQ集群支撑自身业务的case较多，国内各种中小型互联网公司使用RabbitMQ的实践也比较多。 除此之外，RabbitMQ的开源社区很活跃，较高频率的迭代版本，来修复发现的bug以及进行各种优化。 RabbitMQ也有一点缺陷，就是他自身是基于erlang语言开发的，所以导致较为难以分析里面的源码，也较难进行深层次的源码定制和改造，毕竟需要较为扎实的erlang语言功底才可以。 RocketMQ 是阿里开源的，经过阿里的生产环境的超高并发、高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。 而且RocketMQ是基于Java语言开发的，适合深入阅读源码，有需要可以站在源码层面解决线上生产问题，包括源码的二次开发和改造。 Kafka Kafka提供的消息中间件的功能明显较少一些，相对上述几款MQ中间件要少很多。 Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。因此Kafka在大数据领域中配合实时计算技术（比如Spark Streaming、Storm、Flink）使用的较多。但是在传统的MQ中间件使用场景中较少采用。 为什么引入消息中间件 系统解耦 异步调用 流量削峰 所有机器前面部署一层MQ，一旦到了瞬时高峰期，一下涌入每秒几千的请求，就可以积压在MQ里面，然后那一台机器慢慢的处理和消费。 等高峰期过了，再消费一段时间，MQ里积压的数据就消费完毕了。 这个就是很典型的一个MQ的用法，用有限的机器资源承载高并发请求，如果业务场景允许异步削峰，高峰期积压一些请求在MQ里，然后高峰期过了，后台系统在一定时间内消费完毕不再积压的话，那就很适合用这种技术方案。 引入消息中间件有哪些缺点 系统可用性降低 一旦MQ挂了，就会导致系统的核心业务流程中断，本来你要是不引入MQ中间件，那其实就是一些系统之间的调用，但是现在你引入了MQ，就导致你多了一个依赖。一旦多了一个依赖，就会导致你的可用性降低。 一旦引入了MQ中间件，你就必须去考虑这个MQ是如何部署的，如何保证高可用性。 甚至在复杂的高可用的场景下，你还要考虑如果MQ一旦挂了以后，你的系统有没有备用兜底的技术方案，可以保证系统继续运行下去。 系统稳定性降低 MQ消息丢失，可能整个系统会出现业务错乱，数据丢失，严重的bug，用户体验很差等各种问题。 MQ消息重复 MQ消息挤压 分布式一致性问题 下游服务失败怎么办， 下游服务意外宕机RabbitMQ这个中间件默认的一个行为，自动ack，也就是投递完成一条消息就自动确认这个消息处理完毕了。 在编写代码时，如果参数为true，则表示自动ack，所以要设置为false，手动ack 只有完成了仓储调度发货的代码业务逻辑，确保仓库系统收到通知之后，仓储服务才会在代码中手动发送ack消息给RabbitMQ。 此时，RabbitMQ收到了这个ack消息，才会标记对应的订单消息被删除了。 如果说在仓储服务收到了订单消息，但是还没来得及完成仓储调度发货的业务逻辑，那也就绝对不会执行这条订单消息的ack操作，然后RabbitMQ也就不会收到这条订单消息的ack通知。 一旦RabbitMQ发现代表消费者的某个仓储服务实例突然宕机了，而这个仓储服务收到的一些订单消息还没来得及处理，没给自己发送那些消息的ack通知。 此时，RabbitMQ会自动对这条订单消息重发推送给其他在运行中的仓储服务实例，让其他的仓储服务实例去处理这条订单消息。 关于ack机制详情请看ack机制 中间件集群崩溃，保证数据不丢失牵扯到了RabbitMQ的一个较为重要的概念：消息的持久化，用英文来说就是durable机制 然后这里又有一个引申的概念，如果按照我们之前的代码和配置，默认情况下，RabbitMQ一旦宕机就再次重启，就会丢失我们之前创建的queue。所以首先得先让queue是持久化的。 queue，设置为持久化的: 1234567891011channel.queueDeclare( \"warehouse_schedule_delivery\", true, false, false, null); 这样，即使RabbitMQ宕机后重启，也会恢复之前创建好的这个queue。 核心在于第二个参数，第二个参数是true。 他的意思就是说，这个创建的queue是durable的，也就是支持持久化的。 此时还有一个重要的点，就是在你的订单服务发送消息到RabbitMQ的时候，需要定义这条消息也是durable，即持久化的。 123456789channel.basicPublish( \"\", \"warehouse_schedule_delivery\", MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 一旦标记了消息是持久化之后，就会让RabbitMQ把消息持久化写入到磁盘上去，此时如果RabbitMQ还没投递数据到仓储服务，结果就突然宕机了。那么再次重启的时候，就会把磁盘上持久化的消息给加载出来。 但是这里要注意一点，RabbitMQ的消息持久化，是不承诺100%的消息不丢失的。 因为有可能RabbitMQ接收到了消息，但是还没来得及持久化到磁盘，他自己就宕机了，这个时候消息还是会丢失的。 如果要完全100%保证写入RabbitMQ的数据必须落地磁盘，不会丢失，需要依靠其他的机制。 MQ没来得及持久化消息宕机其实这个层面包括2个故障： 数据压根儿没传输过去，比如消息在网络传输到一半的时候因为网络故障就丢了 MQ接收但是还驻留在内存里，没落地到磁盘上，此时MQ集群宕机就会丢数据。 首先，我们得考虑一下作为生产者的订单服务要如何利用RabbitMQ提供的相关功能来实现一个技术方案。 ​ 这个技术方案需要保证：只要订单服务发送出去的消息确认成功了，此时MQ集群就一定已经将消息持久化到磁盘了 详情请看confirm机制 MQ全链路考虑问题汇总 生产端如何保证投递出去的消息不丢失：消息在半路丢失，或者在MQ内存中宕机导致丢失，此时你如何基于MQ的功能保证消息不要丢失？ MQ自身如何保证消息不丢失：起码需要让MQ对消息是有持久化到磁盘这个机制。 消费端如何保证消费到的消息不丢失：如果你处理到一半消费端宕机，导致消息丢失，此时怎么办？","categories":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/tags/MQ/"}]},{"title":"RabbitMQ的ack机制","slug":"RabbitMQ的ack机制","date":"2019-01-16T00:59:10.000Z","updated":"2019-01-17T01:17:13.027Z","comments":true,"path":"2019/01/16/RabbitMQ的ack机制/","link":"","permalink":"http://yoursite.com/2019/01/16/RabbitMQ的ack机制/","excerpt":"","text":"ack机制其实手动ack机制非常的简单，必须要消费者确保自己处理完毕了一个消息，才能手动发送ack给MQ，MQ收到ack之后才会删除这个消息。 如果消费者还没发送ack，自己就宕机了，此时MQ感知到他的宕机，就会重新投递这条消息给其他的消费者实例。 通过这种机制保证消费者实例宕机的时候，数据是不会丢失的。 实现原理：delivery tag如果你写好了一个消费者服务的代码，让他开始从RabbitMQ消费数据，这时这个消费者服务实例就会自己注册到RabbitMQ。 所以，RabbitMQ其实是知道有哪些消费者服务实例存在的。 接着，RabbitMQ就会通过自己内部的一个“basic.delivery”方法来投递消息到仓储服务里去，让他消费消息。 投递的时候，会给这次消息的投递带上一个重要的东西，就是“delivery tag”，你可以认为是本次消息投递的一个唯一标识。 channel就是进行数据传输的一个管道吧。对于每个channel而言，一个“delivery tag”就可以唯一的标识一次消息投递，这个delivery tag大致而言就是一个不断增长的数字。 如果采用手动ack机制，实际上仓储服务每次消费了一条消息，处理完毕完成调度发货之后，就会发送一个ack消息给RabbitMQ服务器，这个ack消息是会带上自己本次消息的delivery tag的。 12345channel.basicAck( delivery.getEnvelope().getDeliveryTag(), false); 然后，RabbitMQ根据哪个channel的哪个delivery tag，不就可以唯一定位一次消息投递了？ 接下来就可以对那条消息删除，标识为已经处理完毕。 这里大家必须注意的一点，就是delivery tag仅仅在一个channel内部是唯一标识消息投递的。 所以说，你ack一条消息的时候，必须是通过接受这条消息的同一个channel来进行。 其实这里还有一个很重要的点，就是我们可以设置一个参数，然后就批量的发送ack消息给RabbitMQ，这样可以提升整体的性能和吞吐量。 比如下面那行代码，把第二个参数设置为true就可以了。 12345channel.basicAck( delivery.getEnvelope().getDeliveryTag(), true); 回顾一下自动ack、手动ack的区别: 实际上默认用自动ack，是非常简单的。RabbitMQ只要投递一个消息出去给仓储服务，那么他立马就把这个消息给标记为删除，因为他是不管仓储服务到底接收到没有，处理完没有的。 所以这种情况下，性能很好，但是数据容易丢失。 如果手动ack，那么就是必须等仓储服务完成商品调度发货以后，才会手动发送ack给RabbitMQ，此时RabbitMQ才会认为消息处理完毕，然后才会标记消息为删除。 这样在发送ack之前，仓储服务宕机，RabbitMQ会重发消息给另外一个仓储服务实例，保证数据不丢。 消息处理失败的消息重发使用nack 就是通知RabbitMQ自己没处理成功消息，然后让RabbitMQ将这个消息再次投递给其他的仓储服务实例尝试去完成调度发货的任务。 我们只要在catch代码块里加入下面的代码即可： 12345channel.basicNack( delivery.getEnvelope().getDeliveryTag(), true); 注意上面第二个参数是true，意思就是让RabbitMQ把这条消息重新投递给其他的仓储服务实例，因为自己没处理成功。 你要是设置为false的话，就会导致RabbitMQ知道你处理失败，但是还是删除这条消息 unack消息的积压问题prefetch count对每个channel（其实对应了一个消费者服务实例，你大体可以这么来认为），RabbitMQ投递消息的时候，都是会带上本次消息投递的一个delivery tag的，唯一标识一次消息投递。 然后，我们进行ack时，也会带上这个delivery tag，基于同一个channel进行ack，ack消息里会带上delivery tag让RabbitMQ知道是对哪一次消息投递进行了ack，此时就可以对那条消息进行删除了。 对于每个channel而言（你就认为是针对每个消费者服务实例吧，比如一个仓储服务实例），其实都有一些处于unack状态的消息。 比如RabbitMQ正在投递一条消息到channel，此时消息肯定是unack状态吧？ 然后仓储服务接收到一条消息以后，要处理这条消息需要耗费时间，此时消息肯定是unack状态吧？ 同时，即使你执行了ack之后，你要知道这个ack他默认是异步执行的，尤其如果你开启了批量ack的话，更是有一个延迟时间才会ack的，此时消息也是unack吧？ RabbitMQ他能够无限制的不停给你的消费者服务实例推送消息吗？ 明显是不能的，如果RabbitMQ给你的消费者服务实例推送的消息过多过快，比如都有几千条消息积压在某个消费者服务实例的内存中。 那么此时这几千条消息都是unack的状态，一直积压着，是不是有可能会导致消费者服务实例的内存溢出？内存消耗过大？甚至内存泄露之类的问题产生？ 所以说，RabbitMQ是必须要考虑一下消费者服务的处理能力的。 解决unack消息挤压问题正是因为这个原因，RabbitMQ基于一个prefetch count来控制这个unack message的数量。 你可以通过channel.basicQos(10)这个方法来设置当前channel的prefetch count。 举个例子，比如你要是设置为10的话，那么意味着当前这个channel里，unack message的数量不能超过10个，以此来避免消费者服务实例积压unack message过多。 这样的话，就意味着RabbitMQ正在投递到channel过程中的unack message，以及消费者服务在处理中的unack message，以及异步ack之后还没完成ack的unack message，所有这些message加起来，一个channel也不能超过10个。 如何设置prefetch count 假如说我们把prefetch count设置的很大，比如说3000，5000，甚至100000，就这样特别大的值，那么此时会如何呢？ 这个时候，在高并发大流量的场景下，可能就会导致消费者服务的内存被快速的消耗掉。 因为假如说现在MQ接收到的流量特别的大，每秒都上千条消息，而且此时你的消费者服务的prefetch count还设置的特别大，就会导致可能一瞬间你的消费者服务接收到了达到prefetch count指定数量的消息。 打个比方，比如一下子你的消费者服务内存里积压了10万条消息，都是unack的状态，反正你的prefetch count设置的是10万。 那么对一个channel，RabbitMQ就会最多容忍10万个unack状态的消息，在高并发下也就最多可能积压10万条消息在消费者服务的内存里。 那么此时导致的结果，就是消费者服务直接被击垮了，内存溢出，OOM，服务宕机，然后大量unack的消息会被重新投递给其他的消费者服务，此时其他消费者服务一样的情况，直接宕机，最后造成雪崩效应。 那么如果反过来呢，我们要是把prefetch count设置的很小会如何呢？ 比如说我们把prefetch count设置为1？此时就必然会导致消费者服务的吞吐量极低。因为你即使处理完一条消息，执行ack了也是异步的。 给你举个例子，假如说你的prefetch count = 1，RabbitMQ最多投递给你1条消息处于unack状态。 此时比如你刚处理完这条消息，然后执行了ack的那行代码，结果不幸的是，ack需要异步执行，也就是需要100ms之后才会让RabbitMQ感知到。 那么100ms之后RabbitMQ感知到消息被ack了，此时才会投递给你下一条消息！ 这就尴尬了，在这100ms期间，你的消费者服务是不是啥都没干啊？ 这不就直接导致了你的消费者服务处理消息的吞吐量可能下降10倍，甚至百倍，千倍，都有这种可能！ RabbitMQ官方给出的建议是prefetch count一般设置在100~300之间 这个状态下可以兼顾吞吐量也很高，同时也不容易造成内存溢出的问题。 但是其实在我们的实践中，这个prefetch count大家完全是可以自己去压测一下的。 比如说慢慢调节这个值，不断加大，观察高并发大流量之下，吞吐量是否越来越大，而且观察消费者服务的内存消耗，会不会OOM、频繁FullGC等问题。","categories":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://yoursite.com/tags/MQ/"}]},{"title":"Java类加载","slug":"java类加载","date":"2018-12-06T07:33:23.000Z","updated":"2018-12-07T10:24:07.616Z","comments":true,"path":"2018/12/06/java类加载/","link":"","permalink":"http://yoursite.com/2018/12/06/java类加载/","excerpt":"","text":"Java类加载机制的七个阶段加载下面是对于加载过程最为官方的描述。 加载阶段是类加载过程的第一个阶段。在这个阶段，JVM 的主要目的是将字节码从各个位置（网络、磁盘等）转化为二进制字节流加载到内存中，接着会为这个类在 JVM 的方法区创建一个对应的 Class 对象，这个 Class 对象就是这个类各种数据的访问入口。 其实加载阶段用一句话来说就是：把代码数据加载到内存中。 验证当 JVM 加载完 Class 字节码文件并在方法区创建对应的 Class 对象之后，JVM 便会启动对该字节码流的校验，只有符合 JVM 字节码规范的文件才能被 JVM 正确执行。这个校验过程大致可以分为下面几个类型： JVM规范校验。JVM 会对字节流进行文件格式校验，判断其是否符合 JVM 规范，是否能被当前版本的虚拟机处理。例如：文件是否是以 0x cafe bene开头，主次版本号是否在当前虚拟机处理范围之内等。 代码逻辑校验。JVM 会对代码组成的数据流和控制流进行校验，确保 JVM 运行该字节码文件后不会出现致命错误。例如一个方法要求传入 int 类型的参数，但是使用它的时候却传入了一个 String 类型的参数。一个方法要求返回 String 类型的结果，但是最后却没有返回结果。代码中引用了一个名为 Apple 的类，但是你实际上却没有定义 Apple 类。 当代码数据被加载到内存中后，虚拟机就会对代码数据进行校验，看看这份代码是不是真的按照JVM规范去写的。 准备当完成字节码文件的校验之后，JVM 便会开始为类变量分配内存并初始化。这里需要注意两个关键点，即内存分配的对象以及初始化的类型。 内存分配的对象。Java 中的变量有「类变量」和「类成员变量」两种类型，「类变量」指的是被 static 修饰的变量，而其他所有类型的变量都属于「类成员变量」。在准备阶段，JVM 只会为「类变量」分配内存，而不会为「类成员变量」分配内存。「类成员变量」的内存分配需要等到初始化阶段才开始。 例如下面的代码在准备阶段，只会为 factor 属性分配内存，而不会为 website 属性分配内存。 12public static int factor = 3;public String website = \"www.cnblogs.com/chanshuyi\"; 初始化的类型。在准备阶段，JVM 会为类变量分配内存，并为其初始化。但是这里的初始化指的是为变量赋予 Java 语言中该数据类型的零值，而不是用户代码里初始化的值。 例如下面的代码在准备阶段之后，sector 的值将是 0，而不是 3。 1public static int sector = 3; 但如果一个变量是常量（被 static final 修饰）的话，那么在准备阶段，属性便会被赋予用户希望的值。例如下面的代码在准备阶段之后，number 的值将是 3，而不是 0。 1public static final int number = 3; 之所以 static final 会直接被复制，而 static 变量会被赋予零值。其实我们稍微思考一下就能想明白了。 两个语句的区别是一个有 final 关键字修饰，另外一个没有。而 final 关键字在 Java 中代表不可改变的意思，意思就是说 number 的值一旦赋值就不会在改变了。既然一旦赋值就不会再改变，那么就必须一开始就给其赋予用户想要的值，因此被 final 修饰的类变量在准备阶段就会被赋予想要的值。而没有被 final 修饰的类变量，其可能在初始化阶段或者运行阶段发生变化，所以就没有必要在准备阶段对它赋予用户想要的值。 解析当通过准备阶段之后，JVM 针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符 7 类引用进行解析。这个阶段的主要任务是将其在常量池中的符号引用替换成直接其在内存中的直接引用。 初始化到了初始化阶段，用户定义的 Java 程序代码才真正开始执行。在这个阶段，JVM 会根据语句执行顺序对类对象进行初始化，一般来说当 JVM 遇到下面 5 种情况的时候会触发初始化： 遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用 JDK1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle实例最后的解析结果 REF_getstatic,REF_putstatic,REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 使用当 JVM 完成初始化阶段之后，JVM 便开始从入口方法开始执行用户的程序代码。 卸载当用户程序代码执行完毕后，JVM 便开始销毁创建的 Class 对象，最后负责运行的 JVM 也退出内存。 实战分析12345678910111213141516171819202122232425262728293031323334353637class Grandpa&#123; static &#123; System.out.println(\"爷爷在静态代码块\"); &#125;&#125; class Father extends Grandpa&#123; static &#123; System.out.println(\"爸爸在静态代码块\"); &#125; public static int factor = 25; public Father() &#123; System.out.println(\"我是爸爸~\"); &#125;&#125;class Son extends Father&#123; static &#123; System.out.println(\"儿子在静态代码块\"); &#125; public Son() &#123; System.out.println(\"我是儿子~\"); &#125;&#125;public class InitializationDemo&#123; public static void main(String[] args) &#123; System.out.println(\"爸爸的岁数:\" + Son.factor); //入口 &#125;&#125; 最终的输出结果是： 123爷爷在静态代码块爸爸在静态代码块爸爸的岁数:25 也许会有人问为什么没有输出「儿子在静态代码块」这个字符串？ 这是因为对于静态字段，只有直接定义这个字段的类才会被初始化（执行静态代码块），因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。 对面上面的这个例子，我们可以从入口开始分析一路分析下去： 首先程序到 main 方法这里，使用标准化输出 Son 类中的 factor 类成员变量，但是 Son 类中并没有定义这个类成员变量。于是往父类去找，我们在 Father 类中找到了对应的类成员变量，于是触发了 Father 的初始化。 但根据我们上面说到的初始化的 5 种情况中的第 3 种，我们需要先初始化 Father 类的父类，也就是先初始化 Grandpa 类再初始化 Father 类。于是我们先初始化 Grandpa 类输出：「爷爷在静态代码块」，再初始化 Father 类输出：「爸爸在静态代码块」。 最后，所有父类都初始化完成之后，Son 类才能调用父类的静态变量，从而输出：「爸爸的岁数：25」。 123456789101112131415161718192021222324252627282930313233343536373839class Grandpa&#123; static &#123; System.out.println(\"爷爷在静态代码块\"); &#125; public Grandpa() &#123; System.out.println(\"我是爷爷~\"); &#125;&#125;class Father extends Grandpa&#123; static &#123; System.out.println(\"爸爸在静态代码块\"); &#125; public Father() &#123; System.out.println(\"我是爸爸~\"); &#125;&#125;class Son extends Father&#123; static &#123; System.out.println(\"儿子在静态代码块\"); &#125; public Son() &#123; System.out.println(\"我是儿子~\"); &#125;&#125;public class InitializationDemo&#123; public static void main(String[] args) &#123; new Son(); //入口 &#125;&#125; 123456爷爷在静态代码块爸爸在静态代码块儿子在静态代码块我是爷爷~我是爸爸~我是儿子~ 虽然我们只是实例化了 Son 对象，但是当子类初始化时会带动父类初始化，因此输出结果就如上面所示。 我们仔细来分析一下上面代码的执行流程： 首先在入口这里我们实例化一个 Son 对象，因此会触发 Son 类的初始化，而 Son 类的初始化又会带动 Father 、Grandpa 类的初始化，从而执行对应类中的静态代码块。因此会输出：「爷爷在静态代码块」、「爸爸在静态代码块」、「儿子在静态代码块」。 当 Son 类完成初始化之后，便会调用 Son 类的构造方法，而 Son 类构造方法的调用同样会带动 Father、Grandpa 类构造方法的调用，最后会输出：「我是爷爷~」、「我是爸爸~」、「我是儿子~」。 下面我们举一个稍微复杂点的例子 123456789101112131415161718192021222324public class Book &#123; public static void main(String[] args) &#123; staticFunction(); &#125; static Book book = new Book(); static &#123; System.out.println(\"书的静态代码块\"); &#125; &#123; System.out.println(\"书的普通代码块\"); &#125; Book() &#123; System.out.println(\"书的构造方法\"); System.out.println(\"price=\" + price +\",amount=\" + amount); &#125; public static void staticFunction()&#123; System.out.println(\"书的静态方法\"); &#125; int price = 110; static int amount = 112;&#125; 12345书的普通代码块书的构造方法price=110,amount=0书的静态代码块书的静态方法 下面我们一步步来分析一下代码的整个执行流程。 在上面两个例子中，因为 main 方法所在类并没有多余的代码，我们都直接忽略了 main 方法所在类的初始化。但在这个例子中，main 方法所在类有许多代码，我们就并不能直接忽略了。 当 JVM 在准备阶段的时候，便会为类变量分配内存和进行初始化。此时，我们的 book 实例变量被初始化为 null，amount 变量被初始化为 0。 当进入初始化阶段后，因为 Book 方法是程序的入口，根据我们上面说到的类初始化的五种情况的第四种：当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。JVM 会对 Book 类进行初始化。 JVM 对 Book 类进行初始化首先是执行类构造器（按顺序收集类中所有静态代码块和类变量赋值语句就组成了类构造器），后执行对象的构造器（先收集成员变量赋值，后收集普通代码块，最后收集对象构造器，最终组成对象构造器）。 对于 Book 类，其类构造方法可以简单表示如下： 123456static Book book = new Book();static&#123; System.out.println(\"书的静态代码块\");&#125;static int amount = 112; 于是首先执行static Book book = new Book();这一条语句，这条语句又触发了类的实例化。与类构造器不同，于是 JVM 执行 Book 类的成员变量，再搜集普通代码块，最后执行类的构造方法，于是其执行语句可以表示如下： 123456789int price = 110;&#123; System.out.println(\"书的普通代码块\");&#125;Book()&#123; System.out.println(\"书的构造方法\"); System.out.println(\"price=\" + price +\", amount=\" + amount);&#125; 于是此时 price 赋予 110 的值，输出：「书的普通代码块」、「书的构造方法」。而此时 price 为 110 的值，而 amount 的赋值语句并未执行，所以只有在准备阶段赋予的零值，所以之后输出「price=110,amount=0」。 当类实例化完成之后，JVM 继续进行类构造器的初始化： 123456static Book book = new Book(); //完成类实例化static&#123; System.out.println(\"书的静态代码块\");&#125;static int amount = 112; 即输出：「书的静态代码块」，之后对 amount 赋予 112 的值。 到这里，类的初始化已经完成，JVM 执行 main 方法的内容。 1234public static void main(String[] args)&#123; staticFunction();&#125; 即输出：「书的静态方法」。 分析方法论从上面几个例子可以看出，分析一个类的执行顺序大概可以按照如下步骤： 确定类变量的初始值。在类加载的准备阶段，JVM 会为类变量初始化零值，这时候类变量会有一个初始的零值。如果是被 final 修饰的类变量，则直接会被初始成用户想要的值。 初始化入口方法。当进入类加载的初始化阶段后，JVM 会寻找整个 main 方法入口，从而初始化 main 方法所在的整个类。当需要对一个类进行初始化时，会首先初始化类构造器，之后初始化对象构造器。 初始化类构造器。初始化类构造器是初始化类的第一步，其会按顺序收集类变量的赋值语句、静态代码块，最终组成类构造器由 JVM 执行。 初始化对象构造器。初始化对象构造器是在类构造器执行完成之后的第二部操作，其会按照执行类成员变成赋值、普通代码块、对象构造方法的顺序收集代码，最终组成对象构造器，最终由 JVM 执行。 如果在初始化 main 方法所在类的时候遇到了其他类的初始化，那么继续按照初始化类构造器、初始化对象构造器的顺序继续初始化。如此反复循环，最终返回 main 方法所在类。","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"线上问题排查","slug":"线上问题排查","date":"2018-12-06T02:53:24.000Z","updated":"2018-12-06T06:30:54.087Z","comments":true,"path":"2018/12/06/线上问题排查/","link":"","permalink":"http://yoursite.com/2018/12/06/线上问题排查/","excerpt":"","text":"高CPU占用一个应用占用CPU很高，除了确实是计算密集型应用之外，通常原因都是出现了死循环。 top 首先根据top命令查看占用cpu过高的线程 这里假设pid 为28855 可以现根据ps aux | grep PID确定哪一进程 ps -mp pid -o THREAD,tid,time 根据ps -mp pid -o THREAD,tid,time命令来找出哪一个线程占用cpu时间过高，可以在后面加上|sort -rn进行排序，方便排查 例如ps -mp 28855 -o THREAD,tid,time|sort -rn 进制转换 将排查到的线程id转换为16进制 printf &quot;%x\\n&quot; tid jstack pid |grep tid -A 30 根据pid，tid，通过jstack去打印线程的堆栈信息，注意tid是16进制的 高内存占用 top命令：Linux命令。可以查看实时的内存使用情况。 jmap -histo:live [pid]，然后分析具体的对象数目和占用内存大小，从而定位代码。 jmap -dump:live,format=b,file=xxx.xxx [pid]，然后利用MAT工具分析是否存在内存泄漏等等。 高IO top top -H -p pid iostat -mx 2 iotop","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Linux常用命令笔记","slug":"Linux常用命令","date":"2018-12-04T01:33:23.000Z","updated":"2018-12-06T01:49:50.825Z","comments":true,"path":"2018/12/04/Linux常用命令/","link":"","permalink":"http://yoursite.com/2018/12/04/Linux常用命令/","excerpt":"","text":"[TOC] 系统监控命令netstat 参数说明 -t : 指明显示TCP端口 -u : 指明显示UDP端口 -l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序) -p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序。 -n : 不进行DNS轮询(可以加速操作) 显示当前服务器上所有端口及进程服务，于grep结合可查看某个具体端口及服务情况 [root@localhost ~]# netstat -nlp |grep LISTEN //查看当前所有监听端口· [root@localhost ~]# netstat -nlp |grep 80 //查看所有80端口使用情况· [root@localhost ~]# netstat -an | grep 3306 //查看所有3306端口使用情况· ## 文件操作命令scpscp [参数] [原路径] [目标路径] 参数说明 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 实例 实例1：从远处复制文件到本地目录 命令： scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 实例2：从远处复制到本地 命令： scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/ 实例3：上传本地文件到远程机器指定目录 命令： scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptest tailtail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 参数说明 -f 该参数用于监视File文件增长。-c Number 从 Number 字节位置读取指定文件-n Number 从 Number 行位置读取指定文件。-m Number 从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。-b Number 从 Number 表示的512字节块位置读取指定文件。-k Number 从 Number 表示的1KB块位置读取指定文件。File 指定操作的目标文件名称上述命令中，都涉及到number，假设不指定，默认显示10行。Number前面可使用正负号，表示该偏移从顶部还是从尾部開始计算。tail可运行文件一般在/usr/bin/以下。 演示例子 tail -f filename说明：监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C tail -n 20 filename说明：显示filename最后20行。 tail -r -n 10 filename说明：逆序显示filename最后10行 补充 跟tail功能相似的命令还有：cat 从第一行開始显示档案内容。tac 从最后一行開始显示档案内容。more 分页显示档案内容。less 与 more 相似，但支持向前翻页head 仅仅显示前面几行tail 仅仅显示后面几行n 带行号显示档案内容od 以二进制方式显示档案内容 tartar [参数] [目标文件] 参数说明 -c: 建立压缩档案-x：解压-t：查看内容-r：向压缩归档文件末尾追加文件-u：更新原压缩包中的文件 这五个是独立的命令，压缩解压都要用到其中一个，可以和别的命令连用但只能用其中一个。下面的参数是根据需要在压缩或解压档案时可选的。 -z：有gzip属性的-j：有bz2属性的-Z：有compress属性的-v：显示所有过程-O：将文件解开到标准输出 下面的参数-f是必须的 -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。 示例 tar -cf all.tar *.jpg这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 tar -rf all.tar *.gif这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 tar -uf all.tar logo.gif这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 tar -tf all.tar这条命令是列出all.tar包中所有文件，-t是列出文件的意思 tar -xf all.tar这条命令是解出all.tar包中所有文件，-x是解开的意思 压缩 tar –cvf jpg.tar *.jpg 将目录里所有jpg文件打包成tar.jpg tar –czf jpg.tar.gz *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz tar –cjf jpg.tar.bz2 *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用bzip2压缩，生成一个bzip2压缩过的包，命名为jpg.tar.bz2 tar –cZf jpg.tar.Z *.jpg 将目录里所有jpg文件打包成jpg.tar后，并且将其用compress压缩，生成一个umcompress压缩过的包，命名为jpg.tar.Z rar a jpg.rar *.jpg rar格式的压缩，需要先下载rar for linux zip jpg.zip *.jpg zip格式的压缩，需要先下载zip for linux 解压 tar –xvf file.tar 解压 tar包 tar -xzvf file.tar.gz 解压tar.gz tar -xjvf file.tar.bz2 解压 tar.bz2 tar –xZvf file.tar.Z 解压tar.Z unrar e file.rar 解压rar unzip file.zip 解压zip 总结 *.tar 用 tar –xvf 解压 *.gz 用 gzip -d或者gunzip 解压 .tar.gz和.tgz 用 tar –xzf 解压 *.bz2 用 bzip2 -d或者用bunzip2 解压 *.tar.bz2用tar –xjf 解压 *.Z 用 uncompress 解压 *.tar.Z 用tar –xZf 解压 *.rar 用 unrar e解压 *.zip 用 unzip 解压","categories":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Hadoop2.6.0集群部署","slug":"Hadoop2.6集群部署文档","date":"2018-12-01T07:33:23.000Z","updated":"2018-12-04T04:26:47.506Z","comments":true,"path":"2018/12/01/Hadoop2.6集群部署文档/","link":"","permalink":"http://yoursite.com/2018/12/01/Hadoop2.6集群部署文档/","excerpt":"","text":"准备 四台虚拟机 要求： 安装好jdk1.8 配置好主机名 /etc/hostname下 配置好主机路由 在/etc/hosts/下 1234xx.xx.xx.xx node1xx.xx.xx.xx ndoe2xx.xx.xx.xx node3xx.xx.xx.xx node4 四台机器全一样 node1与其他机器的免密登录 关闭selinux与防火墙 防火墙：防火墙会引起hadoop相关组件通讯的各种异常 service iptables stop (临时关闭) （systemctl stop firewalld （centos7）） chkconfig iptables off (重启后生效) （systemctl disable firewalld （centos7）） SELINUX： setenforce 0 (临时生效) 修改/etc/selinux/config 下的 SELINUX=disabled （重启后生效）。 规划 | | NN | DN | ZK | ZKFC | JN | RM | NodeM || —– | —- | —- | —- | —- | —- | —- | —– || node1 | 1 | | 1 | 1 | | 1 | || node2 | 1 | 1 | 1 | 1 | 1 | | 1 || node3 | | 1 | 1 | | 1 | | 1 || node4 | | 1 | | | 1 | | 1 | Zookeeper集群部署 在zookeeper/conf/下 把zoo_sample.cfg文件修改为zoo.cfg文件 修改zoo.cfg文件的dataDir，修改为dataDir=/home/hadoop/data/zookeeper 在zoo.cfg中加入以下几项：(此处不能用hostname) 12345server.1=172.16.0.10:2888:3888server.2=172.16.0.11:2888:3888server.3=172.16.0.12:2888:3888 拷贝zoo.cfg到其他节点同目录下（hadoop2，hadoop3） 在/home/hadoop/data/zookeeper目录(无该目录手工创建)下创建myid文件， node1的myid写入1 node2的myid写入2 node3的myid写入3 启动zookeeper：$ZOOKEEPER_HOME/bin/zkServer.sh start Hadoop安装部署解压hadoop安装包 tar -zxvf hadoop-2.6.0.tar.gz 配置文件修改 hadoop/etc/hadoop/hadoop-env.sh 修改export JAVA_HOME=/usr/java/jdk1.8.0_191-amd64 hadoop/etc/hadoop/hdfs-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;zml&lt;/value&gt; //集群名称，自己根据需要修改。后面的都要对应修改&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.namenodes.zml&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; //namenode名称&lt;/property&gt;&lt;property&gt; //nn1的namenode的rpc端口 &lt;name&gt;dfs.namenode.rpc-address.zml.nn1&lt;/name&gt; &lt;value&gt;node1:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.zml.nn2&lt;/name&gt; &lt;value&gt;node2:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //http接口 &lt;name&gt;dfs.namenode.http-address.zml.nn1&lt;/name&gt; &lt;value&gt;node1:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.http-address.zml.nn2&lt;/name&gt; &lt;value&gt;node2:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //journalNode配置，3个节点 &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://node2:8485;node3:8485;node4:8485/zml&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //namenode代理，注意改集群名称 &lt;name&gt;dfs.client.failover.proxy.provider.zml&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //ssh私钥 &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;&lt;value&gt;/root/.ssh/id_dsa&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //journalnode数据目录 &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/jn/data&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //自动切换 &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; core-site.xml 123456789101112131415&lt;configuration&gt;&lt;property&gt; //集群名称 &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://zml&lt;/value&gt;&lt;/property&gt;&lt;property&gt; //zookeeper服务地址 &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt; &lt;/property&gt;&lt;property&gt; //hadoop临时目录修改 &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml 1234&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; yarn-site.xml 12345678910111213141516&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt;&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;&lt;value&gt;node1&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce_shuffle.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;&lt;/property&gt;&lt;configuration&gt; slaves 123node2node3node4 初始化 将node1的etc下的所有配置文件copy到node2，node3，node4上 在node2,node3,node4启动journalNode 在sbin目录下 *hadoop-daemon.sh start journalnode 查看日志看是否报错 jps查看进程是否启动 格式化namenode 在node1的hadoop的bin目录下 ./hdfs namenode -format 启动node1的namenode，在sbin目录下 ./hadoop-daemon.sh start namenode 查看日志是否报错 bin目录下 ./hdfs namenode -bootstrapStandby 这样node2的namenode也就格式化了，可以查看hadoop的data目录下是否有对应的fsimage文件 格式化zkfc 启动第二个namenode 在其中一个namenode上初始化zkfc bin目录下 ./hdfs zkfc-formatZK 停止所有节点 sbin目录下 ./stop-dfs.sh 全面启动sbin目录下 ./start-dfs.sh ./start-yarn.sh","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"mapreduce工作机制","slug":"mapreduce工作机制","date":"2018-11-29T02:53:24.000Z","updated":"2018-11-29T09:57:04.765Z","comments":true,"path":"2018/11/29/mapreduce工作机制/","link":"","permalink":"http://yoursite.com/2018/11/29/mapreduce工作机制/","excerpt":"","text":"第一代工作机制第一代Hadoop，由分布式存储系统HDFS和分布式计算框架MapReduce组成，其中，HDFS由一个NameNode和多个DataNode组成，MapReduce由一个JobTracker和多个TaskTracker组成，对应Hadoop版本为Hadoop 1.x和0.21.X，0.22.x 流程先上图 来多几个图对比下： 提交作业 在作业提交之前，需要对作业进行配置 程序代码，主要是自己书写的MapReduce程序。 输入输出路径 其他配置，如输出压缩等。 配置完成后，通过JobClinet来提交 首先由JobClient的subJobInternal方法提交作业(步骤1 ),并且在waitForCompletion方法中会调用monitorAndPrintJob方法轮询作业的进度，并将进度信自、输出至控制台，我们在WordCount看到的作业进度信息就是由该方法输出的。在JobClient的submitJoblnternal方法中，通过调用JobTracker的getNewJobId方法向JobTracker清求一个作业 ID （步骤2 ).接着检查作业输出目录和输入分片(InputSplit）是否符合要求，将运行作业所需要的资源(包括作业jar文件、第三方jar文件等)复制到 HDFS下特定日录下(步骤3 ),供作业运行时使用。当这些完成后，通过调用JobTracker的submitJob方法告知JobTracker作业准备执行(步骤4)。 作业初始化 客户端提交完成后，JobTracker会将作业加入队列，然后进行调度，默认的调度方法是FIFO调试方式。 当JobTracker收到对其submitJob方法的调用后，会将此调用交由作业调度器进行调度，并对其初始化，创建一个表示正在运行作业的对象(步骤5)。为了给TaskTracke:分配任务，必须先从HDFS系统中获取已计算好的输入分片信息、(步骤6）。然后为每个输入分片创建一个Map任务，而创建的Reduce任务的个数由mapred-site.xml文件的mapred.reduce.tasks配置决定，默认是1，可通过setNumReduceTasks方法针对每个作业设置。此时，Map任务和Reduce任务的任务ID将被指定。 任务的分配 TaskTracker和JobTracker之间的通信与任务的分配是通过心跳机制完成的。 TaskTracker会主动向JobTracker询问是否有作业要做，如果自己可以做，那么就会申请到作业任务，这个任务可以使Map也可能是Reduce任务。 对于map任务和reduce任务，tasktracker有固定数量的任务槽，两者是独立设置的，默认调度器在处理reduce任务槽之前，会填满空闲的map任务槽，因此，如果tasktracker至少有一个闲置的map任务槽，jobtracker会为它选择一个map任务，否则选择一个reduce任务 任务的执行 申请到任务后，TaskTracker会做如下事情： 拷贝代码到本地 拷贝任务的信息到本地 启动JVM运行任务 状态与任务的更新 任务在运行过程中，首先会将自己的状态汇报给TaskTracker，然后由TaskTracker汇总告之JobTracker。 任务进度是通过计数器来实现的。 作业的完成 JobTracker是在接受到最后一个任务运行完成后，才会将任务标志为成功。 此时会做删除中间结果等善后处理工作。 推测执行​ MapReduce计算框架将一个作业分解成一个个Map任务和Reduce任务以便可以并行地运行任务，但是这样一来，作业完成的时间将取决于最慢的任务完成的时间，当作业的任务数到达一定址的时候，出现个别拖慢整个作业进度的任务是很常见的。​ 为了避免这种情况的发生，MapReduce计算框架采取了推测执行的机制(speculativeexecution ) 。当一个任务运行进度比预期要慢的时候，MapReduce计算框架会启动一个相同的任务作为其备份。当一个作业的所有任务都启动之后，MapReduce计算框架会针对某些己经运行一段时问月比作业中其他任务平均进度慢的任务启动一个推测执行的任务。该推测执行的任务与原任务享有同样的地位，也就是说如果推测执行的任务先于原任务完成，则原任务会被关闭，如果原任务先于推测执行的任务完成，则推测执行的任务会被关闭。​ 推测执行的机制有利有弊，它可以改善由于硬件老化等原因引起的作业时间延长，但是如果任务执行缓慢的原因是由于软件缺陷，推测执行对于这种情况是无能为力的，反而会因为大星的兀余任务抢占集群资源、增加网络带宽的负荷量。 第二代工作机制（YARN）YARN（Yet Another Resource Negotiator）对应hadoop版本为0.23.x和2.x 资源管理 扩展 ResourceManagerResourceManager作为资源的协调者有两个主要的组件：Scheduler和ApplicationsManager(AsM)。 Scheduler Scheduler负责分配最少但满足application运行所需的资源量给Application。Scheduler只是基于应用程序资源的使用情况进行调度，资源包括：内存，CPU，磁盘，网络等等，可以看出，这同现 Mapreduce 固定类型的资源使用模型有显著区别，它给集群的使用带来负面的影响。从某种意义上讲它就是一个纯粹的调度器，并不负责监视/跟踪application的状态，当然也不会处理失败的task。RM使用resource container概念来管理集群的资源，每一个应用程序需要不同类型的资源因此就需要不同的容器。resource container是资源的抽象，每个container包括一定的内存、IO、网络等资源，不过目前的实现只包括内存一种资源。ResourceManager 提供一个调度策略的插件，它负责将集群资源分配给多个队列和应用程序。调度插件可以基于现有的能力调度和公平调度模型。 ResourceManager 支持分层级的应用队列，这些队列享有集群一定比例的资源。 ApplicationsManager ApplicationsManager(AsM)负责处理client提交的job以及协商第一个container以供applicationMaster运行，并且在applicationMaster失败的时候会重新启动applicationMaster。 RM具体完成的一些功能 资源调度：Scheduler从所有运行着的application收到资源请求后构建一个全局的资源分配计划，然后根据application特殊的限制以及全局的一些限制条件分配资源。 资源监视：Scheduler会周期性的接收来自NM的资源使用率的监控信息，另外applicationMaster可以从Scheduler得到属于它的已完成的container的状态信息。 Application提交： client向AsM获得一个applicationID client将applicationID以及需要的jar包文件等上传到hdfs的指定目录，由yarn-site.xml的yarn.app.mapreduce.am.staging-dir指定 client构造资源请求的对象以及application的提交上下文发送给AsM AsM接收application的提交上下文 AsM根据application的信息向Scheduler协商一个Container供applicationMaster运行，然后启动applicationMaster 向该container所属的NM发送launchContainer信息启动该container,也即启动applicationMaster、AsM向client提供运行着的AM的状态信息 AM的生命周期：AsM负责系统中所有AM的生命周期的管理。AsM负责AM的启动，当AM启动后，AM会周期性的向AsM发送heartbeat，默认是1s，AsM据此了解AM的存活情况，并且在AM失败时负责重启AM，若是一定时间过后(默认10分钟)没有收到AM的heartbeat，AsM就认为该AM失败了。. NodeManager NM是每一台机器框架的代理，主要负责启动RM分配给AM的container以及代表AM的container，并且会监视container的运行情况。在启动container的时候，NM会设置一些必要的环境变量以及将container运行所需的jar包、文件等从hdfs下载到本地，也就是所谓的资源本地化 当所有准备工作做好后，才会启动代表该container的脚本将程序启动起来。启动起来后，NM会周期性的监视该container运行占用的资源情况 (CPU，内存，硬盘，网络 ) 并且向调度器汇报，若是超过了该container所声明的资源量，则会kill掉该container所代表的进程。 NM还提供了一个简单的服务以管理它所在机器的本地目录。Applications可以继续访问本地目录即使那台机器上已经没有了属于它的container在运行。例如，Map-Reduce应用程序使用这个服务存储map output并且shuffle它们给相应的reduce task 在NM上还可以扩展自己的服务，yarn提供了一个yarn.nodemanager.aux-services的配置项，通过该配置，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的。 在启动一个container的时候，NM就执行该container的default_container_executor.sh，该脚本内部会执行launch_container.sh。launch_container.sh会先设置一些环境变量，最后启动执行程序的命令。对于MapReduce而言，启动AM就执行org.apache.hadoop.mapreduce.v2.app.MRAppMaster；启动map/reduce task就执行org.apache.hadoop.mapred.YarnChild。 ApplicationManager ApplicationMaster是一个框架特殊的库，每一个应用的 ApplicationMaster 的职责有：向调度器索要适当的资源容器，运行任务，跟踪应用程序的状态和监控它们的进程，处理任务的失败原因 对于Map-Reduce计算模型而言有它自己的ApplicationMaster实现，对于其他的想要运行在yarn上的计算模型而言，必须得实现针对该计算模型的ApplicationMaster用以向RM申请资源运行task，比如运行在yarn上的spark框架也有对应的ApplicationMaster实现，归根结底，yarn是一个资源管理的框架，并不是一个计算框架，要想在yarn上运行应用程序，还得有特定的计算框架的实现。由于yarn是伴随着MRv2一起出现的，所以下面简要概述MRv2在yarn上的运行流程 MRv2运行流程 MR JobClient向resourceManager(AsM)提交一个job AsM向Scheduler请求一个供MR AM运行的container，然后启动它 MR AM启动起来后向AsM注册 MR JobClient向AsM获取到MR AM相关的信息，然后直接与MR AM进行通信 MR AM计算splits并为所有的map构造资源请求 MR AM做一些必要的MR OutputCommitter的准备工作 MR AM向RM(Scheduler)发起资源请求，得到一组供map/reduce task运行的container，然后与NM一起对每一个container执行一些必要的任务，包括资源本地化等 MR AM 监视运行着的task 直到完成，当task失败时，申请新的container运行失败的task 当每个map/reduce task完成后，MR AM运行MR OutputCommitter的cleanup 代码，也就是进行一些收尾工作 当所有的map/reduce完成后，MR AM运行OutputCommitter的必要的job commit或者abort APIs MR AM退出。 在Yarn上写应用程序在yarn上写应用程序并不同于我们熟知的MapReduce应用程序，必须牢记yarn只是一个资源管理的框架，并不是一个计算框架，计算框架可以运行在yarn上。我们所能做的就是向RM申请container,然后配合NM一起来启动container。就像MRv2一样，jobclient请求用于MR AM运行的container，设置环境变量和启动命令，然后交由NM去启动MR AM，随后map/reduce task就由MR AM全权负责，当然task的启动也是由MR AM向RM申请container，然后配合NM一起来启动的。所以要想在yarn上运行非特定计算框架的程序，我们就得实现自己的client和applicationMaster。另外我们自定义的AM需要放在各个NM的classpath下，因为AM可能运行在任何NM所在的机器上。 新旧 Hadoop MapReduce 框架比对让我们来对新旧 MapReduce 框架做详细的分析和对比，可以看到有以下几点显著变化： 首先客户端不变，其调用 API 及接口大部分保持兼容，这也是为了对开发使用者透明化，使其不必对原有代码做大的改变 ( 详见 2.3 Demo 代码开发及详解)，但是原框架中核心的 JobTracker 和 TaskTracker 不见了，取而代之的是 ResourceManager, ApplicationMaster 与 NodeManager 三个部分。 我们来详细解释这三个部分，首先 ResourceManager 是一个中心的服务，它做的事情是调度、启动每一个 Job 所属的 ApplicationMaster、另外监控 ApplicationMaster 的存在情况。细心的读者会发现：Job 里面所在的 task 的监控、重启等等内容不见了。这就是 AppMst 存在的原因。ResourceManager 负责作业与资源的调度。接收 JobSubmitter 提交的作业，按照作业的上下文 (Context) 信息，以及从 NodeManager 收集来的状态信息，启动调度过程，分配一个 Container 作为 App Mstr NodeManager 功能比较专一，就是负责 Container 状态的维护，并向 RM 保持心跳。 ApplicationMaster 负责一个 Job 生命周期内的所有工作，类似老的框架中 JobTracker。但注意每一个 Job（不是每一种）都有一个 ApplicationMaster，它可以运行在 ResourceManager 以外的机器上。 Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到： 这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。 在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。 对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。 老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsManager( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。 Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。 参考链接Hadoop 新 MapReduce 框架 Yarn 详解","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"解惑各种mapreduce问题","slug":"解惑各种mapreduce问题","date":"2018-11-28T02:53:24.000Z","updated":"2018-11-28T08:34:31.283Z","comments":true,"path":"2018/11/28/解惑各种mapreduce问题/","link":"","permalink":"http://yoursite.com/2018/11/28/解惑各种mapreduce问题/","excerpt":"","text":"Shuffle的定义是什么？ map task与reduce task的执行是否在不同的节点上？ Shuffle产生的意义是什么？ Shuffle过程的期望可以有：完整地从map task端拉取数据到reduce 端。在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗。减少磁盘IO对task执行的影响。 每个map task都有一个内存缓冲区，存储着map的输出结果，当缓冲区快满的时候需要将缓冲区的数据该如何处理？ 每个map task都有一个内存缓冲区，存储着map的输出结果，当缓冲区快满的时候需要将缓冲区的数据以一个临时文件的方式存放到磁盘，当整个map task结束后再对磁盘中这个map task产生的所有临时文件做合并，生成最终的正式输出文件，然后等待reduce task来拉数据。 在map task执行时，它是如何读取HDFS的？ 读取的Split与block的对应关系可能是什么？ MapReduce提供Partitioner接口，它的作用是什么？ MapReduce提供Partitioner接口，它的作用就是根据key或value及reduce的数量来决定当前的这对输出数据最终应该交由哪个reduce task处理。默认对key hash后再以reduce task数量取模。默认的取模方式只是为了平均reduce的处理能力，如果用户自己对Partitioner有需求，可以订制并设置到job上 溢写是在什么情况下发生？ 在一定条件下将缓冲区中的数据临时写入磁盘，然后重新利用这块缓冲区。这个从内存往磁盘写数据的过程被称为Spill，中文可译为溢写。 溢写是为什么不影响往缓冲区写map结果的线程？ 溢写线程启动时不应该阻止map的结果输出，所以整个缓冲区有个溢写的比例spill.percent。这个比例默认是0.8，也就是当缓冲区的数据已经达到阈值（buffer size spill percent = 100MB 0.8 = 80MB），溢写线程启动，锁定这80MB的内存，执行溢写过程。Map task的输出结果还可以往剩下的20MB内存中写，互不影响 当溢写线程启动后，需要对这80MB空间内的key做排序(Sort)。排序是MapReduce模型默认的行为，这里的排序也是对谁的排序？ 当溢写线程启动后，需要对这80MB空间内的key做排序(Sort)。排序是MapReduce模型默认的行为，这里的排序也是对序列化的字节做的排序 哪些场景才能使用Combiner呢？ Combiner的输出是Reducer的输入，Combiner绝不能改变最终的计算结果。所以从我的想法来看，Combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，且不影响最终结果的场景。比如累加，最大值等。Combiner的使用一定得慎重，如果用好，它对job执行效率有帮助，反之会影响reduce的最终结果。 Merge的作用是什么？ 最终磁盘中会至少有一个这样的溢写文件存在(如果map的输出结果很少，当map执行完成时，只会产生一个溢写文件)，因为最终的文件只有一个，所以需要将这些溢写文件归并到一起，这个过程就叫做Merge reduce中Copy过程采用是什么协议？ Copy过程，简单地拉取数据。Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。 每个reduce task不断地通过RPC从JobTracker那里获取map task是否完成的信息 reduce中merge过程有几种方式，与map有什么相似之处？ merge有三种形式：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘。默认情况下第一种形式不启用，让人比较困惑，是吧。当内存中的数据量到达一定阈值，就启动内存到磁盘的merge。与map 端类似，这也是溢写的过程，这个过程中如果你设置有Combiner，也是会启用的，然后在磁盘中生成了众多的溢写文件。第二种merge方式一直在运行，直到没有map端的数据时才结束，然后启动第三种磁盘到磁盘的merge方式生成最终的那个文件。 溢写过程中如果有很多个key/value对需要发送到某个reduce端去，那么如何处理这些key/value值 如果有很多个key/value对需要发送到某个reduce端去，那么需要将这些key/value值拼接到一块，减少与partition相关的索引记录。 论坛论坛讨论","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"Hadoop概述","slug":"Hadoop","date":"2018-11-27T02:53:24.000Z","updated":"2018-11-27T10:02:28.120Z","comments":true,"path":"2018/11/27/Hadoop/","link":"","permalink":"http://yoursite.com/2018/11/27/Hadoop/","excerpt":"","text":"HDFS的设计 超大文件 流式数据访问 一次写入，多次读取，读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要 商用硬件 Hadoop并不需要运行在昂贵且高可靠的硬件上 低时间延迟的数据访问 几十毫秒范围的应用不适合在HDFS上运行，HDFS是为高数据吞吐量应用优化的，这可能会议提高时间延迟为代价。目前，对于低延迟的访问需求，HBase是更好的选择 大量的小文件 由于namenode将文件系统的元数据存储在内存中，因此该文件系统所能存储的文件总数受限于namenode的内存容量。 多用户写入，任意修改文件 HDFS中的文件可能只有一个writer，而且写操作总是将数据添加在文件的末尾。它不支持多个写入者的操作，也不支持在文件的任意位置进行修改 HDFS的概念数据块 64MB HDFS中小于一个块大小的文件不会占据整个块的空间 HDFS的块比磁盘的块(512字节)大，其目的是为了最小化寻址开销，如果块设置的足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间，因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率 但是这个块也不会设置得过大，MapReduce中的map任务通常一次只处理一个块中的数据，因此如果任务数太少（少于集群中的节点数量），作业的运行速度就会比较慢 好处 一个文件的大小可以大于网络中任意一个磁盘的容量 使用抽象块而非整个文件作为存储单元，大大简化了存储子系统的设计 块还非常适合用于数据备份进而提供数据容错能力和提高可用性 HDFS中fsck可以显示块信息 namenode namenode管理文件系统的命名空间，它维护者文件系统树及整棵树内所有的文件和目录 所有信息以2个文件的形式永久保存在本地磁盘上：命名空间镜像文件和编辑日志文件。 namenode也保存着每个文件中各个块所在的数据节点信息，但并不永久保存，这些信息会在系统启动时由数据节点重建 运行namenode服务的机器毁坏，文件系统上的所欲文件将会丢失，因为我们不知道如何根据datanode的块重建文件，因此对namenode实现容错非常重要 备份那些组成文件系统元数据持久状态的文件。将持久状态写入本地磁盘的同时，写入一个远程挂载的网络文件系统（NFS） 运行一个辅助namenode，但它不能被用作namenode。作用：定期通过编辑日志合并命名空间镜像，以防止编辑日志过大。一般在另一台单独的物理计算器上运行，因为它需要占用大量CPU时间与namenode相同容量的内存来执行合并操作。它会保存合并后的命名空间镜像的副本，并在namenode发生故障时启用。但是，辅助namenode保存的状态总是滞后于主节点，所以在主节点全部失效后，难免会丢失部分数据。在这种情况下，一般把存储在NFS上的namenode元数据复制到辅助namenode并作为新的主namenode运行 datanode datanode是文件系统的工作节点，根据需要存储并检索数据块，并且定期向namenode发送它们所存储的块的列表 联邦HDFS 2.x发型版本系列中引入的联邦HDFS允许通过添加namenode实现扩展，其中每个namenode管理文件系统命名空间中的一部分 HDFS的高可用性 新的namenode直到满足以下情形才能响应服务 将命名空间的映像导入内存中 重做编辑日志 接收到足够多的来自datanode的数据块报告并退出安全模式 在2.x发行版本系列在HDFS中增加了对高可用性的支持 namenode之间需要通过高可用的共享存储实现边记日志的共享 datanode需要同时向两个namenode发送数据块处理报告 客户端需要使用特定的机制来处理namenode的失效问题，这一机制对用户是透明的","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://yoursite.com/tags/hadoop/"}]},{"title":"线程池阻塞提交","slug":"线程池阻塞提交","date":"2018-11-13T07:33:23.000Z","updated":"2018-11-13T09:24:06.853Z","comments":true,"path":"2018/11/13/线程池阻塞提交/","link":"","permalink":"http://yoursite.com/2018/11/13/线程池阻塞提交/","excerpt":"","text":"问题简介在使用线程池时当池内线程数达到max，并且队列满的时候，后submit的任务会被拒绝，默认的采用拒绝策略，在实际业务中想要控制实际的任务量，当超过某个任务数量时采用阻塞的方式提交，而不是产生拒绝任务的异常 解决方法 注意点 通过重写offer阻塞替代ThreadPoolExecutor超出maxPoolSize时抛出的reject异常 根据ThreadPoolExecutor的execute逻辑, 使用此阻塞的前提为corePoolSize必须与maxPoolSize一致,否则会造成池中的线程无法扩充问题. 此前考虑使用Semaphore, 但对于锁的释放不好控制 实现代码 123456789101112131415sharedExecutorService = new ThreadPoolExecutor(sharedExtractWorkerPoolSize, sharedExtractWorkerPoolSize, 10, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(1) &#123; private static final long serialVersionUID = 1L; @Override public boolean offer(Runnable e) &#123; try &#123; // turn offer() and add() into a blocking calls (unless interrupted) put(e); return true; &#125; catch(InterruptedException ie) &#123; Thread.currentThread().interrupt(); &#125; return false; &#125; &#125;); 参考链接：https://stackoverflow.com/questions/4521983/java-executorservice-that-blocks-on-submission-after-a-certain-queue-size","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"事务","slug":"事务","date":"2018-11-09T07:33:23.000Z","updated":"2018-11-09T02:52:40.955Z","comments":true,"path":"2018/11/09/事务/","link":"","permalink":"http://yoursite.com/2018/11/09/事务/","excerpt":"","text":"事务的特性ACID 原子性 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性 执行事务前后，数据保持一致； 隔离性 并发访问数据库时，一个用户的事物不被其他事物所干扰，各并发事务之间数据库是独立的； 持久性 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响 事务属性隔离级别并发事务带来的问题 脏读（Dirty read） 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 丢失修改（Lost to modify） 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。 不可重复读（Unrepeatableread） 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 幻读（Phantom read） 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。 不可重复度和幻读区别： 不可重复读的重点是修改，幻读的重点在于新增或者删除。 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。 隔离级别 Spring中的TransactionDefinition定义了5个隔离级别 TransactionDefinition.ISOLATION_DEFAULT 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别 TransactionDefinition.ISOLATION_READ_UNCOMMITTED 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 事务传播行为当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。在TransactionDefinition定义中包括了如下几个表示传播行为的常量 支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRED 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 不支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRES_NEW 创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER 以非事务方式运行，如果当前存在事务，则抛出异常。 其他情况 TransactionDefinition.PROPAGATION_NESTED 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 这里需要指出的是，前面的六种事务传播行为是 Spring 从 EJB 中引入的，他们共享相同的概念。而 PROPAGATION_NESTED 是 Spring 所特有的。以 PROPAGATION_NESTED 启动的事务内嵌于外部事务中（如果存在外部事务的话），此时，内嵌事务并不是一个独立的事务，它依赖于外部事务的存在，只有通过外部的事务提交，才能引起内部事务的提交，嵌套的子事务不能单独提交。如果熟悉 JDBC 中的保存点（SavePoint）的概念，那嵌套事务就很容易理解了，其实嵌套的子事务就是保存点的一个应用，一个事务中可以包括多个保存点，每一个嵌套子事务。另外，外部事务的回滚也会导致嵌套子事务的回滚。 事务超时属性所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。 事务只读属性事务的只读属性是指，对事务性资源进行只读操作或者是读写操作。所谓事务性资源就是指那些被事务管理的资源，比如数据源、 JMS 资源，以及自定义的事务性资源等等。如果确定只对事务性资源进行只读操作，那么我们可以将事务标志为只读的，以提高事务处理的性能。在 TransactionDefinition 中以 boolean 类型来表示该事务是否只读。 回滚规则这些规则定义了哪些异常会导致事务回滚而哪些不会。默认情况下，事务只有遇到运行期异常时才会回滚，而在遇到检查型异常时不会回滚（这一行为与EJB的回滚行为是一致的）。 但是你可以声明事务在遇到特定的检查型异常时像遇到运行期异常那样回滚。同样，你还可以声明事务遇到特定的异常不回滚，即使这些异常是运行期异常。","categories":[{"name":"概念","slug":"概念","permalink":"http://yoursite.com/categories/概念/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"事务","slug":"事务","permalink":"http://yoursite.com/tags/事务/"}]},{"title":"CGLIB用法介绍","slug":"CGLIB用法介绍","date":"2018-10-30T07:33:23.000Z","updated":"2019-04-16T09:51:35.441Z","comments":true,"path":"2018/10/30/CGLIB用法介绍/","link":"","permalink":"http://yoursite.com/2018/10/30/CGLIB用法介绍/","excerpt":"","text":"CGLIB简介CGLib（Code Generation Library）是一个高效的代码生成库，底层实现是使用asm来转换字节码生成类。在生成代理类的场景中，由于JDK动态代理必须要求源对象有实现接口，而实际场景中，并不是所有类都有实现接口，因此使用CGLib可以用在未实现接口的类上。 值得注意的几点是： 使用CGLib代理的类不能是final修饰的，因为代理类需要继承主题类； final修饰的方法不会被切入； 如果主题类的构造函数不是默认空参数的，那么在使用Enhancer类create的时候，选择create(java.lang.Class[] argumentTypes, java.lang.Object[] arguments) 方法。 接下来认识实现动态代理最重要的一个接口 MethodInteceptor 123456789101112131415161718192021222324252627package net.sf.cglib.proxy; /** * General-purpose &#123;@link Enhancer&#125; callback which provides for \"around advice\". * @author Juozas Baliuka &lt;a href=\"mailto:baliuka@mwm.lt\"&gt;baliuka@mwm.lt&lt;/a&gt; * @version $Id: MethodInterceptor.java,v 1.8 2004/06/24 21:15:20 herbyderby Exp $ */public interface MethodInterceptorextends Callback&#123; /** * All generated proxied methods call this method instead of the original method. * The original method may either be invoked by normal reflection using the Method object, * or by using the MethodProxy (faster). * @param obj \"this\", the enhanced object * @param method intercepted Method * @param args argument array; primitive types are wrapped * @param proxy used to invoke super (non-intercepted method); may be called * as many times as needed * @throws Throwable any exception may be thrown; if so, super method will not be invoked * @return any value compatible with the signature of the proxied method. Method returning void will ignore this value. * @see MethodProxy */ public Object intercept(Object obj, java.lang.reflect.Method method, Object[] args, MethodProxy proxy) throws Throwable; &#125; MethodInterceptor，从名字上方法拦截器，就是对方法做切入的。intercept方式的4个参数分别对应增强对象、调用方法、方法参数以及调用父类方法的代理。 用法介绍先定义一个主题对象 123456789101112131415161718192021222324252627282930public class DBQuery &#123; public DBQuery() &#123; &#125; public DBQuery(Integer i) &#123; System.out.println(\"Here's in DBQuery Constructor\"); &#125; public String getElement(String id) &#123; return id + \"_CGLib\"; &#125; public List&lt;String&gt; getAllElements() &#123; return Arrays.asList(\"Hello_CGLib1\", \"Hello_CGLib2\"); &#125; public String methodForNoop() &#123; return \"Hello_Noop\"; &#125; public String methodForFixedValue(String param) &#123; return \"Hello_\" + param; &#125; public final String sayHello() &#123; return \"Hello Everyone！\"; &#125;&#125; 单回调切入类 12345678public class DBQueryProxy implements MethodInterceptor &#123; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Here in interceptor ！\"); return methodProxy.invokeSuper(o, objects); &#125;&#125; test class: 12345678910111213141516public class TestCGLibProxy &#123; public static void main(String[] args) &#123; DBQueryProxy dbQueryProxy = new DBQueryProxy(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(DBQuery.class); enhancer.setCallback(dbQueryProxy);// DBQuery dbQuery = (DBQuery)enhancer.create(new Class[]&#123;Integer.class&#125;, new Object[]&#123;1&#125;); DBQuery dbQuery = (DBQuery) enhancer.create(); System.out.println(dbQuery.getElement(\"Hello\")); System.out.println(); System.out.println(dbQuery.getAllElements()); System.out.println(); System.out.println(dbQuery.sayHello()); &#125;&#125; result: 多回调MethodInterceptor: 1234567public class DBQueryProxy2 implements MethodInterceptor &#123; public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Here in interceptor 2！\"); return methodProxy.invokeSuper(o, objects); &#125;&#125; test class: 1234567891011121314151617181920212223242526public class TestCGLibProxy &#123; public static void main(String[] args) &#123; DBQueryProxy dbQueryProxy = new DBQueryProxy(); DBQueryProxy2 dbQueryProxy2 = new DBQueryProxy2(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(DBQuery.class); enhancer.setCallbacks(new Callback[]&#123;dbQueryProxy, dbQueryProxy2&#125;); enhancer.setCallbackFilter(new CallbackFilter() &#123; public int accept(Method method) &#123; if (method.getName().equals(\"getElement\")) &#123; return 0; &#125; else &#123; return 1; &#125; &#125; &#125;); DBQuery dbQuery = (DBQuery) enhancer.create(); System.out.println(\"========Inteceptor By DBQueryProxy ========\"); System.out.println(dbQuery.getElement(\"Hello\")); System.out.println(); System.out.println(\"========Inteceptor By DBQueryProxy2 ========\"); System.out.println(dbQuery.getAllElements()); &#125;&#125; result: 不处理利用枚举常量 Callback noopCb = NoOp.INSTANCE; test class: 1234567891011121314151617181920212223242526272829303132public class TestCGLibProxy &#123; public static void main(String[] args) &#123; DBQueryProxy dbQueryProxy = new DBQueryProxy(); DBQueryProxy2 dbQueryProxy2 = new DBQueryProxy2(); Callback noopCb = NoOp.INSTANCE; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(DBQuery.class); enhancer.setCallbacks(new Callback[]&#123;dbQueryProxy, dbQueryProxy2, noopCb&#125;); enhancer.setCallbackFilter(new CallbackFilter() &#123; public int accept(Method method) &#123; if (method.getName().equals(\"getElement\")) &#123; return 0; &#125; else if (method.getName().equals(\"getAllElements\")) &#123; return 1; &#125; else &#123; return 2; &#125; &#125; &#125;); DBQuery dbQuery = (DBQuery) enhancer.create(); System.out.println(\"========Inteceptor By DBQueryProxy ========\"); System.out.println(dbQuery.getElement(\"Hello\")); System.out.println(); System.out.println(\"========Inteceptor By DBQueryProxy2 ========\"); System.out.println(dbQuery.getAllElements()); System.out.println(); System.out.println(\"========Return Original Value========\"); System.out.println(dbQuery.methodForNoop()); &#125;&#125; result: 固定值需要实现FixedValue接口，会忽略原来函数的返回值，使用固定值来替换 1234567public class DBQueryProxyFixedValue implements FixedValue &#123; public Object loadObject() throws Exception &#123; System.out.println(\"Here in DBQueryProxyFixedValue ! \"); return \"Fixed Value\"; &#125;&#125; test class: 12345678910111213141516171819202122232425262728293031323334353637383940public class TestCGLibProxy &#123; public static void main(String[] args) &#123; DBQueryProxy dbQueryProxy = new DBQueryProxy(); DBQueryProxy2 dbQueryProxy2 = new DBQueryProxy2(); Callback noopCb = NoOp.INSTANCE; Callback fixedValue = new DBQueryProxyFixedValue(); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(DBQuery.class); enhancer.setCallbacks(new Callback[]&#123;dbQueryProxy, dbQueryProxy2, noopCb, fixedValue&#125;); enhancer.setCallbackFilter(new CallbackFilter() &#123; public int accept(Method method) &#123; if (method.getName().equals(\"getElement\")) &#123; return 0; &#125; else if (method.getName().equals(\"getAllElements\")) &#123; return 1; &#125; else if (method.getName().equals(\"methodForNoop\")) &#123; return 2; &#125; else if (method.getName().equals(\"methodForFixedValue\")) &#123; return 3; &#125; else &#123; return 0; &#125; &#125; &#125;); DBQuery dbQuery = (DBQuery) enhancer.create(); System.out.println(\"========Inteceptor By DBQueryProxy ========\"); System.out.println(dbQuery.getElement(\"Hello\")); System.out.println(); System.out.println(\"========Inteceptor By DBQueryProxy2 ========\"); System.out.println(dbQuery.getAllElements()); System.out.println(); System.out.println(\"========Return Original Value========\"); System.out.println(dbQuery.methodForNoop()); System.out.println(); System.out.println(\"========Return Fixed Value========\"); System.out.println(dbQuery.methodForFixedValue(\"myvalue\")); &#125;&#125; result: 懒加载CGLib的懒加载，可以用在一些不需要立即加载完整对象实例的场景，比如说Hibernate中的查询对象，如果这个对象有关联其他对象，这个时候不会马上将关联对象一起查询出来关联，要等到调用到这个关联对象时才去做查询。利用CGLib的懒加载机制，可以很好的实现这个需求。需要了解2个接口，LazyLoader和Dispatcher。这两个接口的定义如下 1234567public interface LazyLoader extends Callback &#123; Object loadObject() throws Exception;&#125; public interface Dispatcher extends Callback &#123; Object loadObject() throws Exception;&#125; 它们都继承了Callback接口，都有一个loadObject的方法，区别在于LazyLoader只有在第一次调用时，会执行loadObject获取对象，而Dispatcher会在每次调用时都触发loadObject方法， example: 123456789@Data@NoArgsConstructor@AllArgsConstructorpublic class Schedule &#123; private String courseName; private Date courseTime;&#125; 12345678910111213public class ScheduleLazyLoader implements LazyLoader &#123; public Object loadObject() throws Exception &#123; System.out.println(\"before LazyLoader init...you can query from db...\"); Schedule schedule = new Schedule(); schedule.setCourseName(\"English\"); Calendar calendar = Calendar.getInstance(); calendar.set(2017,3,28); schedule.setCourseTime(calendar.getTime()); System.out.println(\"after LazyLoader init...\"); return schedule; &#125;&#125; 12345678910111213public class ScheduleDispatcher implements Dispatcher &#123; public Object loadObject() throws Exception &#123; System.out.println(\"before Dispatcher init...you can query from db...\"); Schedule schedule = new Schedule(); schedule.setCourseName(\"Math\"); Calendar calendar = Calendar.getInstance(); calendar.set(2017,4,1); schedule.setCourseTime(calendar.getTime()); System.out.println(\"after Dispatcher init...\"); return schedule; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738@Datapublic class Student &#123; private int id; private String name; /** * 英语课时间表 */ private Schedule EnglishSchedule; /** * 数学课时间表 */ private Schedule MathSchedule; public Student(int id, String name) &#123; this.id = id; this.name = name; this.EnglishSchedule = createEnglishSchedule(); this.MathSchedule = createMathSchedule(); &#125; private Schedule createEnglishSchedule() &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Schedule.class); enhancer.setCallback(new ScheduleLazyLoader()); return (Schedule) enhancer.create(); &#125; private Schedule createMathSchedule() &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Schedule.class); enhancer.setCallback(new ScheduleDispatcher()); return (Schedule) enhancer.create(); &#125;&#125; test class: 1234567891011121314151617181920public class LazyLoadTest &#123; public static void main(String[] args) &#123; Student student = new Student(666, \"XiaoMing\"); System.out.println(\"id=\" + student.getId()); System.out.println(\"name=\" + student.getName()); // LazyLoader 只有第一次，Dispatcher是每次都会进loadObject的方法 System.out.println(\"========First Get EnglishSchedule ========\"); System.out.println(student.getEnglishSchedule()); System.out.println(); System.out.println(\"========First Get MathSchedule ========\"); System.out.println(student.getMathSchedule()); System.out.println(); System.out.println(\"========Second Get EnglishSchedule ========\"); System.out.println(student.getEnglishSchedule()); System.out.println(); System.out.println(\"========Second Get MathSchedule ========\"); System.out.println(student.getMathSchedule()); &#125;&#125; result: githubgithub","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"cglib","slug":"cglib","permalink":"http://yoursite.com/tags/cglib/"}]},{"title":"spring集成jetty","slug":"spring集成jetty","date":"2018-10-12T00:59:10.000Z","updated":"2018-10-12T01:57:31.656Z","comments":true,"path":"2018/10/12/spring集成jetty/","link":"","permalink":"http://yoursite.com/2018/10/12/spring集成jetty/","excerpt":"","text":"简介在后端程序模块的开发中，需要监听端口请求，springboot中内置了tomcat，可以方便的使用，但是对于spring来说，使用jetty是一个比较好的选择 集成实现maven引入相关jar包12345678910111213141516171819202122232425262728&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-deploy&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt; &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.woodstox&lt;/groupId&gt; &lt;artifactId&gt;woodstox-core-asl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;/dependency&gt; 在xml中配置jetty相关的jetty-context.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd\"&gt; &lt;bean id=\"contextHandlerCollection\" class=\"org.eclipse.jetty.server.handler.ContextHandlerCollection\"/&gt; &lt;bean id=\"jettyServer\" class=\"org.eclipse.jetty.server.Server\" destroy-method=\"stop\"&gt; &lt;constructor-arg name=\"pool\"&gt; &lt;bean class=\"org.eclipse.jetty.util.thread.QueuedThreadPool\"&gt; &lt;constructor-arg name=\"minThreads\" value=\"$&#123;jetty.poolSize.minThreads&#125;\" /&gt; &lt;constructor-arg name=\"maxThreads\" value=\"$&#123;jetty.poolSize.maxThreads&#125;\" /&gt; &lt;/bean&gt; &lt;/constructor-arg&gt; &lt;property name=\"stopAtShutdown\" value=\"true\" /&gt; &lt;property name=\"stopTimeout\" value=\"3000\" /&gt; &lt;property name=\"connectors\"&gt; &lt;array&gt; &lt;bean class=\"org.eclipse.jetty.server.ServerConnector\"&gt; &lt;constructor-arg name=\"server\" ref=\"jettyServer\" /&gt; &lt;property name=\"port\" value=\"$&#123;jetty.port&#125;\" /&gt; &lt;property name=\"acceptQueueSize\" value=\"1024\" /&gt; &lt;property name=\"idleTimeout\" value=\"60000\" /&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;property name=\"handler\"&gt; &lt;bean class=\"org.eclipse.jetty.server.handler.HandlerCollection\"&gt; &lt;property name=\"handlers\"&gt; &lt;list&gt; &lt;ref bean=\"contextHandlerCollection\" /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;property name=\"beans\"&gt; &lt;list&gt; &lt;ref bean=\"deploymentManager\" /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"deploymentManager\" class=\"org.eclipse.jetty.deploy.DeploymentManager\"&gt; &lt;property name=\"contexts\" ref=\"contextHandlerCollection\" /&gt; &lt;property name=\"appProviders\"&gt; &lt;list&gt; &lt;ref bean=\"webAppProvider\" /&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"webAppProvider\" class=\"org.eclipse.jetty.deploy.providers.WebAppProvider\"&gt; &lt;property name=\"monitoredDirName\" value=\"webapps\" /&gt; &lt;property name=\"scanInterval\" value=\"10\" /&gt; &lt;property name=\"extractWars\" value=\"true\" /&gt; &lt;property name=\"configurationManager\"&gt; &lt;bean class=\"org.eclipse.jetty.deploy.PropertiesConfigurationManager\" /&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; server-context.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.3.xsd \"&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- rest mtreceiver --&gt; &lt;bean id=\"bootstrap\" class=\"com.***.***.***.server.Bootstrap\"&gt; &lt;property name=\"jettyServer\" ref=\"jettyServer\" /&gt; &lt;/bean&gt; &lt;bean id=\"contentNegotiationManager\" class=\"org.springframework.web.accept.ContentNegotiationManagerFactoryBean\"&gt; &lt;property name=\"defaultContentType\" value=\"application/json;charset=utf-8\" /&gt; &lt;/bean&gt; &lt;mvc:annotation-driven content-negotiation-manager=\"contentNegotiationManager\"&gt; &lt;mvc:message-converters&gt; &lt;bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\"&gt; &lt;property name=\"objectMapper\"&gt; &lt;bean class=\"com.fasterxml.jackson.databind.ObjectMapper\"&gt; &lt;property name=\"serializationInclusion\"&gt; &lt;value type=\"com.fasterxml.jackson.annotation.JsonInclude.Include\"&gt;NON_NULL&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!--&lt;mvc:interceptors&gt;--&gt; &lt;!--&lt;mvc:interceptor&gt;--&gt; &lt;!--&lt;mvc:mapping path=\"/**\" /&gt;--&gt; &lt;!--&lt;bean class=\"com.***.***.template.security.AuthInterceptor\"&gt;--&gt; &lt;!--&lt;property name=\"account\" value=\"$&#123;security.auth.account&#125;\" /&gt;--&gt; &lt;!--&lt;property name=\"sharedSecret\" value=\"$&#123;security.auth.sharedSecret&#125;\" /&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt; &lt;!--&lt;/mvc:interceptor&gt;--&gt; &lt;!--&lt;/mvc:interceptors&gt;--&gt;&lt;/beans&gt; 启动类相关Bootstrap.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * 服务生命周期辅助程序, 用于: * 1. 优雅关闭API服务, 加入JVM钩子, 保护数据. * 2. 可用于缓存持久化至数据库, 文件等操作 */public final class Bootstrap implements InitializingBean, ApplicationListener&lt;ContextRefreshedEvent&gt; &#123; private static final Logger LOG = LoggerFactory.getLogger(Bootstrap.class); private Server jettyServer; /** * @return true: no error, false: has error */ private boolean doStop() &#123; try &#123; jettyServer.stop(); // 1. Gracefully shutdown return true; &#125; catch (Exception e) &#123; LOG.error(\"Shutdown jetty server error: \", e); &#125; return false; &#125; @Override public void afterPropertiesSet() throws Exception &#123; Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; if (doStop()) &#123; LOG.info(\"Shutdown completed\"); &#125; else &#123; LOG.warn(\"Shutdown completed with error, please check logs !!!\"); &#125; &#125; &#125;); LOG.info(\"Added JVM shutdown hook ...\"); &#125; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; if (event.getApplicationContext().getParent() == null) &#123; // Notify when ROOT CONTEXT loaded try &#123; /* * Start Jetty container after all bean have been initialize. * * 1.In case of load big data from DB slowly but the WEB PORT * have been open, some request maybe send to here but * application can't process them. * * 2. Jetty will parse web.xml, DispatcherServlet need WebApplicationContext to make * handlerMapping (URL -&gt; process bean), so if the Spring Container haven't load * controllers specified on \"springmvc-context.xml\" and Jetty parse web.xml, * springmvc maybe not found the beans, finally will throw 404 error to client. */ jettyServer.start(); &#125; catch (Exception e) &#123; LOG.error(\"Start jetty server error: \", e); System.exit(1); throw new RuntimeException(e); &#125; &#125; &#125; public void setJettyServer(Server jettyServer) &#123; this.jettyServer = jettyServer; &#125; &#125; CustomDispatcherServlet.java 123456789public class CustomDispatcherServlet extends DispatcherServlet &#123; private static final long serialVersionUID = 1L; public CustomDispatcherServlet() &#123; super(ApplicationContextKeeper.getWebAppCtx()); &#125;&#125; StartServer.java 123456789101112public class StartServer &#123; private static final Logger LOG = LoggerFactory.getLogger(StartServer.class); @SuppressWarnings(&#123; \"unused\", \"resource\" &#125;) public static void main(String[] args) &#123; LOG.info(\"Starting server ......\"); ApplicationContext context = new ClassPathXmlApplicationContext(\"application-context.xml\"); LOG.info(\"Server started!\"); &#125;&#125; 项目内目录下添加webapps web.xml 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:web=\"http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" id=\"WebApp_ID\" version=\"3.0\"&gt; &lt;display-name&gt;Search Server&lt;/display-name&gt; &lt;!-- 关闭Jetty默认的列出文件列表功能, 提高安全性 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;default&lt;/servlet-name&gt; &lt;servlet-class&gt;org.eclipse.jetty.servlet.DefaultServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;dirAllowed&lt;/param-name&gt; &lt;param-value&gt;false&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;com.xuanwu.dsap.template.server.CustomDispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;detectAllHandlerAdapters&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/v1.0/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 测试请求1234567891011121314151617181920@Controller@RequestMapping(\"/extract\")public class TemplateExtractController &#123; private static final Logger LOG = LoggerFactory.getLogger(TemplateExtractController.class); @RequestMapping(value = \"/task\", method = RequestMethod.POST, consumes = &#123;MediaType.APPLICATION_JSON_VALUE&#125;, produces = &#123;MediaType.APPLICATION_JSON_VALUE&#125;) @ResponseBody public Resp test(@RequestBody @Valid TestReq testReq)&#123; try &#123; System.out.println(\"111111111111111\"); return new Resp(ResponseCode.INVALID_ACCEPT); &#125; catch (Exception e) &#123; LOG.error(\"SMS Pack export error\", e); return Resp.with(ResponseCode.SERVICE_UNAVAILABLE); &#125; &#125;&#125; 附：jetty与Tomcat对比Tomcat 和 Jetty 都是作为一个 Servlet 引擎应用的比较广泛，可以将它们比作为中国与美国的关系，虽然 Jetty 正常成长为一个优秀的 Servlet 引擎，但是目前的 Tomcat 的地位仍然难以撼动。相比较来看，它们都有各自的优点与缺点。 Tomcat 经过长时间的发展，它已经广泛的被市场接受和认可，相对 Jetty 来说 Tomcat 还是比较稳定和成熟，尤其在企业级应用方面，Tomcat 仍然是第一选择。但是随着 Jetty 的发展，Jetty 的市场份额也在不断提高，至于原因就要归功与 Jetty 的很多优点了，而这些优点也是因为 Jetty 在技术上的优势体现出来的。 架构比较 从架构上来说，显然 Jetty 比 Tomcat 更加简单，如果你对 Tomcat 的架构还不是很了解的话，建议你先看一下《Tomcat系统架构与设计模式》这篇文章。 Jetty 的架构从前面的分析可知，它的所有组件都是基于 Handler 来实现，当然它也支持 JMX。但是主要的功能扩展都可以用 Handler 来实现。可以说 Jetty 是面向 Handler 的架构，就像 Spring 是面向 Bean 的架构，iBATIS 是面向 statement 一样，而 Tomcat 是以多级容器构建起来的，它们的架构设计必然都有一个“元神”，所有以这个“元神“构建的其它组件都是肉身。 从设计模板角度来看 Handler 的设计实际上就是一个责任链模式，接口类 HandlerCollection 可以帮助开发者构建一个链，而另一个接口类 ScopeHandler 可以帮助你控制这个链的访问顺序。另外一个用到的设计模板就是观察者模式，用这个设计模式控制了整个 Jetty 的生命周期，只要继承了 LifeCycle 接口，你的对象就可以交给 Jetty 来统一管理了。所以扩展 Jetty 非常简单，也很容易让人理解，整体架构上的简单也带来了无比的好处，Jetty 可以很容易被扩展和裁剪。 相比之下，Tomcat 要臃肿很多，Tomcat 的整体设计上很复杂，前面说了 Tomcat 的核心是它的容器的设计，从 Server 到 Service 再到 engine 等 container 容器。作为一个应用服务器这样设计无口厚非，容器的分层设计也是为了更好的扩展，这是这种扩展的方式是将应用服务器的内部结构暴露给外部使用者，使得如果想扩展 Tomcat，开发人员必须要首先了解 Tomcat 的整体设计结构，然后才能知道如何按照它的规范来做扩展。这样无形就增加了对 Tomcat 的学习成本。不仅仅是容器，实际上 Tomcat 也有基于责任链的设计方式，像串联 Pipeline 的 Vavle 设计也是与 Jetty 的 Handler 类似的方式。要自己实现一个 Vavle 与写一个 Handler 的难度不相上下。表面上看，Tomcat 的功能要比 Jetty 强大，因为 Tomcat 已经帮你做了很多工作了，而 Jetty 只告诉，你能怎么做，如何做，有你去实现。 打个比方，就像小孩子学数学，Tomcat 告诉你 1+1=2，1+2=3，2+2=4 这个结果，然后你可以根据这个方式得出 1+1+2=4，你要计算其它数必须根据它给你的公式才能计算，而 Jetty 是告诉你加减乘除的算法规则，然后你就可以根据这个规则自己做运算了。所以你一旦掌握了 Jetty，Jetty 将变得异常强大。 性能比较 单纯比较 Tomcat 与 Jetty 的性能意义不是很大，只能说在某种使用场景下，它表现的各有差异。因为它们面向的使用场景不尽相同。从架构上来看 Tomcat 在处理少数非常繁忙的连接上更有优势，也就是说连接的生命周期如果短的话，Tomcat 的总体性能更高。 而 Jetty 刚好相反，Jetty 可以同时处理大量连接而且可以长时间保持这些连接。例如像一些 web 聊天应用非常适合用 Jetty 做服务器，像淘宝的 web 旺旺就是用 Jetty 作为 Servlet 引擎。 另外由于 Jetty 的架构非常简单，作为服务器它可以按需加载组件，这样不需要的组件可以去掉，这样无形可以减少服务器本身的内存开销，处理一次请求也是可以减少产生的临时对象，这样性能也会提高。另外 Jetty 默认使用的是 NIO 技术在处理 I/O 请求上更占优势，Tomcat 默认使用的是 BIO，在处理静态资源时，Tomcat 的性能不如 Jetty。 特性比较 作为一个标准的 Servlet 引擎，它们都支持标准的 Servlet 规范，还有 Java EE 的规范也都支持，由于 Tomcat 的使用的更加广泛，它对这些支持的更加全面一些，有很多特性 Tomcat 都直接集成进来了。但是 Jetty 的应变更加快速，这一方面是因为 Jetty 的开发社区更加活跃，另一方面也是因为 Jetty 的修改更加简单，它只要把相应的组件替换就好了，而 Tomcat 的整体结构上要复杂很多，修改功能比较缓慢。所以 Tomcat 对最新的 Servlet 规范的支持总是要比人们预期的要晚。","categories":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/categories/spring/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"jetty","slug":"jetty","permalink":"http://yoursite.com/tags/jetty/"}]},{"title":"String的intern()","slug":"String的intern()","date":"2018-09-26T00:54:18.000Z","updated":"2018-09-26T01:11:04.577Z","comments":true,"path":"2018/09/26/String的intern()/","link":"","permalink":"http://yoursite.com/2018/09/26/String的intern()/","excerpt":"","text":"String.intern方法究竟做了什么 Returns a canonical representation for the string object. A pool of strings, initially empty, is maintained privately by the class String. When the intern method is invoked, if the pool already contains a string equal to this String object as determined by the equals(Object) method, then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned. It follows that for any two strings s and t, s.intern() == t.intern() is true if and only if s.equals(t) is true. All literal strings and string-valued constant expressions are interned. String literals are defined in section 3.10.5 of the The Java? Language Specification. 上面是jdk源码中对intern方法的详细解释。简单来说就是intern用来返回常量池中的某字符串，如果常量池中已经存在该字符串，则直接返回常量池中该对象的引用。否则，在常量池中加入该对象，然后 返回引用 String设计的初衷Java中的String被设计成不可变的，出于以下几点考虑： 字符串常量池的需要。字符串常量池的诞生是为了提升效率和减少内存分配。可以说我们编程有百分之八十的时间在处理字符串，而处理的字符串中有很大概率会出现重复的情况。正因为String的不可变性，常量池很容易被管理和优化。 安全性考虑。正因为使用字符串的场景如此之多，所以设计成不可变可以有效的防止字符串被有意或者无意的篡改。从java源码中String的设计中我们不难发现，该类被final修饰，同时所有的属性都被final修饰，在源码中也未暴露任何成员变量的修改方法。（当然如果我们想，通过反射或者Unsafe直接操作内存的手段也可以实现对所谓不可变String的修改）。 作为HashMap、HashTable等hash型数据key的必要。因为不可变的设计，jvm底层很容易在缓存String对象的时候缓存其hashcode，这样在执行效率上会大大提升。 String.intern探究 new String都是在堆上创建字符串对象。当调用 intern() 方法时，编译器会将字符串添加到常量池中（stringTable维护），并返回指向该常量的引用。 通过字面量赋值创建字符串（如：String str=”twm”）时，会先在常量池中查找是否存在相同的字符串，若存在，则将栈中的引用直接指向该字符串；若不存在，则在常量池中生成一个字符串，再将栈中的引用指向该字符串 常量字符串的“+”操作，编译阶段直接会合成为一个字符串。如string str=”JA”+”VA”，在编译阶段会直接合并成语句String str=”JAVA”，于是会去常量池中查找是否存在”JAVA”,从而进行创建或引用。 对于final字段，编译期直接进行了常量替换（而对于非final字段则是在运行期进行赋值处理的）。 final String str1=”ja”;final String str2=”va”;String str3=str1+str2;在编译时，直接替换成了String str3=”ja”+”va”，根据第三条规则，再次替换成String str3=”JAVA” 常量字符串和变量拼接时（如：String str3=baseStr + “01”;）会调用stringBuilder.append()在堆上创建新的对象 JDK 1.7后，intern方法还是会先去查询常量池中是否有已经存在，如果存在，则返回常量池中的引用，这一点与之前没有区别，区别在于，如果在常量池找不到对应的字符串，则不会再将字符串拷贝到常量池，而只是在常量池中生成一个对原字符串的引用。简单的说，就是往常量池放的东西变了：原来在常量池中找不到时，复制一个副本放到常量池，1.7后则是将在堆上的地址引用复制到常量池。 eg1: 1234String str2 = new String(\"str\")+new String(\"01\");str2.intern();String str1 = \"str01\";System.out.println(str2==str1); 在JDK 1.7下，当执行str2.intern();时，因为常量池中没有“str01”这个字符串，所以会在常量池中生成一个对堆中的“str01”的引用(注意这里是引用 ，就是这个区别于JDK 1.6的地方。在JDK1.6下是生成原字符串的拷贝)，而在进行String str1 = “str01”;字面量赋值的时候，常量池中已经存在一个引用，所以直接返回了该引用，因此str1和str2都指向堆中的同一个字符串，返回true。 1234String str2 = new String(\"str\")+new String(\"01\");String str1 = \"str01\";str2.intern();System.out.println(str2==str1); 将中间两行调换位置以后，因为在进行字面量赋值（String str1 = “str01″）的时候，常量池中不存在，所以str1指向的常量池中的位置，而str2指向的是堆中的对象，再进行intern方法时，对str1和str2已经没有影响了，所以返回false。 常见面试题123456789101112131415161718192021222324252627282930313233343536Q：下列程序的输出结果： String s1 = “abc”; String s2 = “abc”; System.out.println(s1 == s2); A：true，均指向常量池中对象。Q：下列程序的输出结果： String s1 = new String(“abc”); String s2 = new String(“abc”); System.out.println(s1 == s2); A：false，两个引用指向堆中的不同对象。Q：下列程序的输出结果： String s1 = “abc”; String s2 = “a”; String s3 = “bc”; String s4 = s2 + s3; System.out.println(s1 == s4); A：false，因为s2+s3实际上是使用StringBuilder.append来完成，会生成不同的对象。Q：下列程序的输出结果： String s1 = “abc”; final String s2 = “a”; final String s3 = “bc”; String s4 = s2 + s3; System.out.println(s1 == s4); A：true，因为final变量在编译后会直接替换成对应的值，所以实际上等于s4=”a”+”bc”，而这种情况下，编译器会直接合并为s4=”abc”，所以最终s1==s4。Q：下列程序的输出结果： String s = new String(“abc”); String s1 = “abc”; String s2 = new String(“abc”); System.out.println(s == s1.intern()); System.out.println(s == s2.intern()); System.out.println(s1 == s2.intern()); A：false，false，true。","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"方便扩展的定时任务","slug":"定时任务","date":"2018-09-18T03:35:27.000Z","updated":"2019-01-16T06:26:32.452Z","comments":true,"path":"2018/09/18/定时任务/","link":"","permalink":"http://yoursite.com/2018/09/18/定时任务/","excerpt":"","text":"定时任务模块在项目中经常会设置个定时任务，用于获取更新缓存，更新系统配置等等，在本篇文章列举了使用延时队列来实现的方式 核心代码SyncTask接口1234567891011121314/** * @Description 可变周期同步任务，需要同步的任务实现该类 * @Version 1.0.0 */public interface SyncTask extends Runnable &#123; /** * 同步周期，更新后，在下一周期生效 * * @return */ public long getPeriod();&#125; SyncBossTask定时任务处理实现类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class SyncBossTask implements Runnable &#123; private Logger logger = LoggerFactory.getLogger(SyncBossTask.class); //使用延时队列 private DelayQueue&lt;InnerSyncTask&gt; tasks = new DelayQueue&lt;InnerSyncTask&gt;(); private Executor executor; public void init() &#123; executor.execute(this); &#125; //从队列中取出任务执行 @Override public void run() &#123; while (true) &#123; try &#123; InnerSyncTask innerTask = tasks.take(); executor.execute(innerTask); &#125; catch (Throwable t) &#123; logger.error(\"Sync boss task exception: \", t); &#125; &#125; &#125; //定时任务的进一步封装类 private class InnerSyncTask implements Delayed, Runnable &#123; SyncTask task; long sTime; long delay; public InnerSyncTask(SyncTask task) &#123; this.task = task; &#125; @Override public void run() &#123; try &#123; task.run(); &#125; finally &#123; resetDelay(); tasks.add(this); &#125; &#125; @Override public int compareTo(Delayed o) &#123; InnerSyncTask other = (InnerSyncTask) o; return sTime &gt; other.sTime ? 1 : (sTime &lt; other.sTime ? -1 : 0); &#125; @Override public long getDelay(TimeUnit unit) &#123; if (sTime - System.currentTimeMillis() &gt; delay) &#123; return 0; &#125; return unit.convert(sTime - System.currentTimeMillis(), TimeUnit.MILLISECONDS); &#125; public void resetDelay() &#123; long period = task.getPeriod(); this.sTime = System.currentTimeMillis() + period; this.delay = period; &#125; &#125; public void setTasks(List&lt;SyncTask&gt; tasks) &#123; if (ListUtil.isBlank(tasks)) return; for (SyncTask task : tasks) &#123; InnerSyncTask innerTask = new InnerSyncTask(task); innerTask.resetDelay(); this.tasks.add(innerTask); &#125; &#125; public void setExecutor(Executor executor) &#123; this.executor = executor; &#125;&#125; 实现自己的业务定时任务代码123456789101112131415161718192021@Componentpublic class Config implements SyncTask &#123; private static final Logger logger = LoggerFactory.getLogger(Config.class); //定时执行周期 private long period = 10 * 60 * 1000; @PostConstruct public void init()&#123; //do something.... &#125; @Override public void run() &#123; //do something... &#125; @Override public long getPeriod() &#123; return period; &#125;&#125; 添加任务此处分两种方式 xml配置 1234567891011121314151617181920 &lt;bean id=\"taskExecutor\" class=\"org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor\"&gt; &lt;property name=\"corePoolSize\" value=\"16\" /&gt; &lt;property name=\"keepAliveSeconds\" value=\"200\" /&gt; &lt;property name=\"maxPoolSize\" value=\"25\" /&gt; &lt;property name=\"queueCapacity\" value=\"60\" /&gt;&lt;/bean&gt;&lt;bean id=\"syncBossTask\" class=\"com.*.*.config.SyncBossTask\" init-method=\"init\"&gt; &lt;property name=\"executor\" ref=\"taskExecutor\" /&gt; &lt;property name=\"tasks\"&gt; &lt;list&gt; &lt;ref bean=\"config\" /&gt; . . .//此处添加任务 &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; java代码配置 123456789101112131415161718192021222324252627282930@Configurationpublic class TaskConfig &#123; @Autowired private Config config; @Bean public SyncBossTask syncBossTask() &#123; SyncBossTask syncBossTask = new SyncBossTask(); syncBossTask.setExecutor(taskExecutor()); syncBossTask.setTasks(syncTasks()); return syncBossTask; &#125; @Bean public ThreadPoolTaskExecutor taskExecutor() &#123; ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); taskExecutor.setKeepAliveSeconds(200); taskExecutor.setQueueCapacity(60); taskExecutor.setCorePoolSize(16); taskExecutor.setMaxPoolSize(25); return taskExecutor; &#125; @Bean public List&lt;SyncTask&gt; syncTasks() &#123; List&lt;SyncTask&gt; tasks = new ArrayList&lt;&gt;(); tasks.add(config); return tasks; &#125;&#125;","categories":[{"name":"项目","slug":"项目","permalink":"http://yoursite.com/categories/项目/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"项目","slug":"项目","permalink":"http://yoursite.com/tags/项目/"}]},{"title":"Thread.Join()","slug":"Thread.Join()","date":"2018-09-06T07:37:36.000Z","updated":"2018-09-06T07:59:19.682Z","comments":true,"path":"2018/09/06/Thread.Join()/","link":"","permalink":"http://yoursite.com/2018/09/06/Thread.Join()/","excerpt":"","text":"Join()作用 t.join()方法只会使主线程进入等待池并等待t线程执行完毕后才会被唤醒。并不影响同一时刻处在运行状态的其他线程。 代码实例解析首先定义一个线程类 1234567891011121314class ThreadTest extends Thread &#123; private String name; public ThreadTest(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 1; i &lt;= 3; i++) &#123; System.out.println(name + \"-\" + i); &#125; &#125;&#125; 不使用join 123456789public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub ThreadTest t1=new ThreadTest(\"A\"); ThreadTest t2=new ThreadTest(\"B\"); t1.start(); t2.start(); &#125;&#125; 输出的结果为： 123456789101112131415161718192021222324------------------第一次---------------main endA-1B-1B-2B-3A-2A-3------------------第二次---------------main endA-1A-2A-3B-1B-2B-3------------------第三次---------------main endB-1B-2B-3A-1A-2A-3 可见，输出的结果是随机的，并且main线程总是最先结束的，即主线程执行完后，子线程交叉执行 使用join 1234567891011public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub ThreadTest t1=new ThreadTest(\"A\"); ThreadTest t2=new ThreadTest(\"B\"); t1.start(); t1.join(); t2.start(); System.out.println(Thread.currentThread().getName()+\" end\"); &#125;&#125; 输出结果为： 1234567A-1A-2A-3main endB-1B-2B-3 结果可见，在main线程执行t1.join后，B线程需要等A线程执行完毕之后才能执行，需要注意的是，t1.join()需要等t1.start()执行之后执行才有效果，此外，如果t1.join()放在t2.start()之后的话，仍然会是交替执行，然而并不是没有效果 看源码1234567891011121314151617181920212223public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); //join(0)等同于wait(0)，即wait无限时间直到被notify &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125; &#125; 可以看出，join()方法的底层是利用wait()方法实现的。可以看出，join方法是一个同步方法，当主线程调用t1.join()方法时，主线程先获得了t1对象的锁，随后进入方法，调用了t1对象的wait()方法，使主线程进入了t1对象的等待池，此时，A线程则还在执行，并且随后的t2.start()还没被执行，因此，B线程也还没开始。等到A线程执行完毕之后，主线程继续执行，走到了t2.start()，B线程才会开始执行。 后续代码实例测试 三个线程不加join 1234567891011121314151617public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub System.out.println(Thread.currentThread().getName()+\" start\"); ThreadTest t1=new ThreadTest(\"A\"); ThreadTest t2=new ThreadTest(\"B\"); ThreadTest t3=new ThreadTest(\"C\"); System.out.println(\"t1start\"); t1.start(); System.out.println(\"t1end\"); System.out.println(\"t2start\"); t2.start(); System.out.println(\"t2end\"); System.out.println(\"t3start\"); t3.start(); System.out.println(\"t3end\"); System.out.println(Thread.currentThread().getName()+\" end\"); &#125; 输出结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354----------------first-----------main startt1startt1endt2startt2endt3startt3endA-1A-2A-3C-1C-2C-3main endB-1B-2B-3-------------------second---------main startt1startt1endt2startt2endt3startt3endmain endA-1A-2A-3B-1B-2B-3C-1C-2C-3-------------third---------------main startt1startt1endt2startt2endt3startA-1A-2A-3t3endmain endB-1B-2B-3C-1C-2C-3 A、B、C和主线程交替运行 加入join 123456789101112131415161718public static void main(String[] args) throws InterruptedException &#123; // TODO Auto-generated method stub System.out.println(Thread.currentThread().getName()+\" start\"); ThreadTest t1=new ThreadTest(\"A\"); ThreadTest t2=new ThreadTest(\"B\"); ThreadTest t3=new ThreadTest(\"C\"); System.out.println(\"t1start\"); t1.start(); System.out.println(\"t1end\"); System.out.println(\"t2start\"); t2.start(); t1.join(); System.out.println(\"t2end\"); System.out.println(\"t3start\"); t3.start(); System.out.println(\"t3end\"); System.out.println(Thread.currentThread().getName()+\" end\"); &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253main startt1startt1endt2startA-1A-2A-3B-1B-2B-3t2endt3startt3endmain endC-1C-2C-3------------------------------main startt1startt1endt2startA-1A-2A-3B-1t2endt3startB-2t3endmain endC-1C-2C-3B-3-------------------------------main startt1startt1endt2startB-1A-1B-2A-2A-3B-3t2endt3startt3endmain endC-1C-2C-3 主线程在t1.join()方法处停止，并需要等待A线程执行完毕后才会执行t3.start()，然而，并不影响B线程的执行。因此，可以得出结论，t.join()方法只会使主线程进入等待池并等待t线程执行完毕后才会被唤醒。并不影响同一时刻处在运行状态的其他线程。","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"java多线程","slug":"java多线程","permalink":"http://yoursite.com/tags/java多线程/"}]},{"title":"定位及优化SQL语句的性能问题","slug":"定位及优化SQL语句的性能问题","date":"2018-09-05T02:38:48.000Z","updated":"2018-09-05T03:31:04.993Z","comments":true,"path":"2018/09/05/定位及优化SQL语句的性能问题/","link":"","permalink":"http://yoursite.com/2018/09/05/定位及优化SQL语句的性能问题/","excerpt":"","text":"执行计划基本语法 1explain select ... mysql的explain 命令可以用来分析select 语句的运行效果。 除此之外，explain 的extended 扩展能够在原本explain的基础上额外的提供一些查询优化的信息，这些信息可以通过mysql的show warnings命令得到。 另外，对于分区表的查询，需要使用partitions命令。 1explain partitions select ... 执行计划包含的信息 id 由一组数字组成。表示一个查询中各个子查询的执行顺序; id相同执行顺序由上至下。 id不同，id值越大优先级越高，越先被执行 id为null时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。 select_type | id | select_type | description || — | ———— |:————————- || 1 | SIMPLE | 不包含任何子查询或union等查询 || 2 | PRIMARY | 包含子查询最外层查询就显示为PRIMARY || 3 | SUBQUERY | 在select或where字句中包含的查询 || 4 | DERIVED | from字句中包含的查询 || 5 | UNION | 出现在union后的查询语句中 || 6 | UNION RESULT | 从UNION中获取结果集 | table 查询涉及到的数据表。 如果查询使用了别名，那么这里显示的是别名，如果不涉及对数据表的操作，那么这显示为null，如果显示为尖括号括起来的就表示这个是临时表，后边的N就是执行计划中的id，表示结果来自于这个查询产生。如果是尖括号括起来的，与类似，也是一个临时表，表示这个结果来自于union查询的id为M,N的结果集 type 访问类型 ALL 扫描全表数据 index遍历索引 range索引范围查找 index_subquery在子查询中使用 ref unique_subquery在子查询中使用 eq_ref ref_or_null对Null进行索引的优化的 ref fulltext使用全文索引 ref 使用非唯一索引查找数据 eq_ref在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。 const使用主键或者唯一索引，且匹配的结果只有一条记录。 system const连接类型的特例，查询的表为系统表。 性能从好到差依次为：system，const，eq_ref，ref，fulltext，ref_or_null，unique_subquery，index_subquery，range，index_merge，index，ALL，除了ALL之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引。 possible_keys 可能使用的索引，注意不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为NULL时就要考虑当前的SQL是否需要优化了。 key 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。 TIPS:查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中。 select_type为index_merge时，这里可能出现两个以上的索引，其他的select_type这里只会出现一个。 key_length 索引长度 char()、varchar()索引长度的计算公式： 1(Character Set：utf8mb4=4,utf8=3,gbk=2,latin1=1) * 列长度 + 1(允许null) + 2(变长列) int 索引长度：int类型占4位，允许null,索引长度为5。 tinyint类型：在NOT NULL 和 NULL 的时候 分别是1和2 bigint类型：NOT NULL 和 NULL值的时候，分别是8和9 smallint类型：NOT NULL 和 NULL值的时候，分别是2和3 mediumint：NOT NULL 和 NULL值的时候，分别是3和4 timestamp类型：NOT NULL 和 NULL的时候，分别是4和5 date类型：在NOT NULL和NULL的时候，分别是3和4 datetime类型在5.6中字段长度是5个字节 float类型：NOT NULL和NULL的时候，分别是4和5 double类型：NOT NULL和NULL的时候，分别是8和9 ref 返回估算的结果集数目，注意这并不是一个准确值。 rows 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 extra extra的信息非常丰富，常见的有： Using index 使用覆盖索引 Using where 使用了用where子句来过滤结果集 Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。 Using temporary 使用了临时表。 一些SQL优化建议 尽量全值匹配复杂索引的所有列和where的条件完全匹配 最佳左前缀法则如果索引了多列，要遵守最左前缀法则，指的是查询从索引的最左前列开始并且不跳过索引中的列 不在索引列上做任何操作不在索引列上进行任何操作，包括计算，函数，类型转换，会导致索引失效而变成全表扫描 范围条件放最后存储引擎不能使用索引中范围条件右边的列 覆盖索引尽量用Extra:Using index即查询的列和索引创建顺序一一匹配 不等于要慎用mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用索引会导致全表扫描，如果要使用，则要使用覆盖索引解决 NUll/Not Null有影响表结构某字段是Not Null的时候，在查询过程中，null/not null会导致全表扫描，，但是如果没有用not null修饰，则会使用索引 Like查询要当心%如果写在前面会导致索引失效，写在右边不会导致索引失效，若一定要使用左边%，则使用覆盖索引 字符类型加引号不加引号会导致类型转换，即全表扫描 OR改UNION效率高使用or会导致索引失效，若必须用or则使用覆盖索引 12345678可以使用select id from t where num=10union allselect id from t where num=20替代select id from t where num=10 or num=20 尽量避免使用in和not 在 where 子句中使用 in和not in，引擎将放弃使用索引而进行全表扫描。 123456可以使用select id from t where num between 10 and 20替代select id from t where num in (10,20) 任何地方都不要使用 select from t ，用具体的字段列表代替“”，不要返回用不到的任何字段。 总结全职匹配我最爱，最做前缀要遵守带头大哥不能死，中间兄弟不能断索引列上少计算，范围之后全失效Like百分写最右，覆盖索引不写*不等空值还有OR，索引影响要注意VAR引号不可丢，SQL优化有诀窍","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"J.U.C之并发工具类","slug":"J.U.C之并发工具类","date":"2018-08-31T01:31:51.000Z","updated":"2018-09-05T02:50:43.151Z","comments":true,"path":"2018/08/31/J.U.C之并发工具类/","link":"","permalink":"http://yoursite.com/2018/08/31/J.U.C之并发工具类/","excerpt":"","text":"CyclicBarrierCyclicBarrier，一个同步辅助类，在API中是这么介绍的： 它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 通俗点讲就是：让一组线程到达一个屏障时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。 12345678910111213141516171819202122232425262728public class CyclicBarrierTest &#123; private static CyclicBarrier cyclicBarrier; static class CyclicBarrierThread extends Thread&#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + \"到了\"); //等待 try&#123; cyclicBarrier.await(); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;public static void main(String[] args)&#123; cyclicBarrier = new CyclicBarrier(5, new Runnable() &#123; @Override public void run() &#123; System.out.println(\"人到齐了，开会吧....\"); &#125; &#125;); for(int i = 0; i &lt; 5; i++)&#123; new CyclicBarrierThread().start(); &#125;&#125;&#125; Semaphore信号量Semaphore是一个控制访问多个共享资源的计数器，和CountDownLatch一样，其本质上是一个“共享锁”。 Semaphore，在API是这么介绍的：一个计数信号量。 从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。 Semaphore 通常用于限制可以访问某些资源（物理或逻辑的）的线程数目。 下面我们就一个停车场的简单例子来阐述Semaphore： 为了简单起见我们假设停车场仅有5个停车位，一开始停车场没有车辆所有车位全部空着，然后先后到来三辆车，停车场车位够，安排进去停车，然后又来三辆，这个时候由于只有两个停车位，所有只能停两辆，其余一辆必须在外面候着，直到停车场有空车位，当然以后每来一辆都需要在外面候着。当停车场有车开出去，里面有空位了，则安排一辆车进去（至于是哪辆 要看选择的机制是公平还是非公平）。 从程序角度看，停车场就相当于信号量Semaphore，其中许可数为5，车辆就相对线程。当来一辆车时，许可数就会减 1 ，当停车场没有车位了（许可书 == 0 ），其他来的车辆需要在外面等候着。如果有一辆车开出停车场，许可数 + 1，然后放进来一辆车。 号量Semaphore是一个非负整数（&gt;=1）。当一个线程想要访问某个共享资源时，它必须要先获取Semaphore，当Semaphore &gt;0时，获取该资源并使Semaphore – 1。如果Semaphore值 = 0，则表示全部的共享资源已经被其他线程全部占用，线程必须要等待其他线程释放资源。当线程释放资源时，Semaphore则+1 123456789101112131415161718192021222324252627282930313233343536373839404142public class SemaphoreTest&#123;static class Parking&#123; //信号量 private Semaphore semaphore; public Parking(int count) &#123; this.semaphore = new Semaphore(count); &#125; public void park()&#123; try &#123; semaphore.acquire(); long time = (long)(Math.random() * 10); System.out.println(Thread.currentThread().getName() + \"进入停车场，停车\" + time + \"秒...\"); Thread.sleep(time*1000); System.out.println(Thread.currentThread().getName() + \"开出停车场...\"); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;finally &#123; semaphore.release(); &#125; &#125; &#125; static class Car extends Thread&#123; Parking parking; Car(Parking parking)&#123; this.parking = parking; &#125; @Override public void run()&#123; parking.park(); &#125; &#125; public static void main(String[] args) &#123; Parking parking = new Parking(3); for (int i = 0; i &lt; 5; i++) &#123; new Car(parking).start(); &#125; &#125; CountDownLatchCyclicBarrier所描述的是“允许一组线程互相等待，直到到达某个公共屏障点，才会进行后续任务”，而CountDownLatch所描述的是”在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待“。在API中是这样描述的： 用给定的计数 初始化 CountDownLatch。由于调用了 countDown() 方法，所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。 CountDownLatch是通过一个计数器来实现的，当我们在new 一个CountDownLatch对象的时候需要带入该计数器值，该值就表示了线程的数量。每当一个线程完成自己的任务后，计数器的值就会减1。当计数器的值变为0时，就表示所有的线程均已经完成了任务，然后就可以恢复等待的线程继续执行了。 虽然，CountDownlatch与CyclicBarrier有那么点相似，但是他们还是存在一些区别的： CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier 123456789101112131415161718192021222324252627282930313233343536public class CountDownLatchTest &#123; private static CountDownLatch countDownLatch = new CountDownLatch(5); static class BossThread extends Thread&#123; @Override public void run()&#123; System.out.println(\"Boss在会议室等待，总共有\" + countDownLatch.getCount() + \"个人开会...\"); try &#123; //boss等待 countDownLatch.await(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; System.out.println(\"所有人都已经到齐了，开会吧...\"); &#125; &#125; static class EmployeeThread extends Thread&#123; @Override public void run()&#123; System.out.println(Thread.currentThread().getName() + \"，到达会议室....\"); countDownLatch.countDown(); &#125; &#125; public static void main(String[] args) &#123; //boss线程启动 new BossThread().start(); for (int i = 0; i &lt; countDownLatch.getCount(); i++) &#123; new EmployeeThread().start(); &#125; &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"并发","slug":"并发","permalink":"http://yoursite.com/tags/并发/"}]},{"title":"HttpClient出现大量CLOSE_WAIT","slug":"HttpClient出现大量CLOSE_WAIT","date":"2018-08-28T07:56:24.000Z","updated":"2018-09-05T02:37:34.911Z","comments":true,"path":"2018/08/28/HttpClient出现大量CLOSE_WAIT/","link":"","permalink":"http://yoursite.com/2018/08/28/HttpClient出现大量CLOSE_WAIT/","excerpt":"","text":"bug描述项目中一个web后端创建http请求到一个search_server模块请求数据，期间出现了大量的CLOSE_WAIT，一遇到CLOSE_WAIT就说明链接没有正常关闭，具体如下 一直处于CLOSE_WAIT肯定是不好的，关闭不了白白占着资源，在网上也查了许多资料，说什么代码有些资源没有关闭，但是完全不存在，， 相关tcp知识TCP协议端口的连接状态 LISTENING 提供某种服务，侦听远方TCP端口的连接请求，当提供的服务没有被连接时，处于LISTENING状态，端口是开放的，等待被连接。 SYN_SENT (客户端状态) 客户端调用connect，发送一个SYN请求建立一个连接，在发送连接请求后等待匹配的连接请求，此时状态为SYN_SENT. SYN_RECEIVED (服务端状态) 在收到和发送一个连接请求后，等待对方对连接请求的确认，当服务器收到客户端发送的同步信号时，将标志位ACK和SYN置1发送给客户端，此时服务器端处于SYN_RCVD状态，如果连接成功了就变为ESTABLISHED，正常情况下SYN_RCVD状态非常短暂。 ESTABLISHED ESTABLISHED状态是表示两台机器正在传输数据 FIN-WAIT-1 等待远程TCP连接中断请求，或先前的连接中断请求的确认，主动关闭端应用程序调用close，TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态。 FIN-WAIT-2 从远程TCP等待连接中断请求，主动关闭端接到ACK后，就进入了FIN-WAIT-2 .这是在关闭连接时，客户端和服务器两次握手之后的状态，是著名的半关闭的状态了，在这个状态下，应用程序还有接受数据的能力，但是已经无法发送数据，但是也有一种可能是，客户端一直处于FIN_WAIT_2状态，而服务器则一直处于WAIT_CLOSE状态，而直到应用层来决定关闭这个状态。 CLOSE-WAIT 等待从本地用户发来的连接中断请求 ，被动关闭端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT. CLOSING 等待远程TCP对连接中断的确认,处于此种状态比较少见 LAST-ACK 等待原来的发向远程TCP的连接中断请求的确认,被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接,TCP也发送一个 FIN,等待对方的ACK.进入LAST-ACK TIME-WAIT 在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态,等待足够的时间以确保远程TCP接收到连接中断请求的确认,很大程度上保证了双方都可以正常结束,但是也存在问题，须等待2MSL时间的过去才能进行下一次连接。 CLOSED 被动关闭端在接受到ACK包后，就进入了closed的状态，连接结束，没有任何连接状态。 附TCP正常连接建立和终止所对应的状态图 解决方案添加如下类即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class IdleConnectionMonitor implements Runnable, InitializingBean &#123; private static final Logger LOG = LoggerFactory.getLogger(IdleConnectionMonitor.class); private HttpClientConnectionManager httpConnMgr; private volatile boolean shutdown = false; private int idleSeconds = 30; @Override public void run() &#123; try &#123; while (!shutdown) &#123; synchronized (this) &#123; wait(5000); httpConnMgr.closeExpiredConnections(); httpConnMgr.closeIdleConnections(idleSeconds, TimeUnit.SECONDS); &#125; &#125; &#125; catch (InterruptedException ex) &#123; LOG.error(\"Idle connection monitor interrupted !\"); &#125; &#125; @Override public void afterPropertiesSet() throws Exception &#123; if (!shutdown) &#123; new Thread(this).start(); LOG.info(\"Idle connection monitor started !\"); &#125; &#125; public void shutdown() &#123; shutdown = true; synchronized (this) &#123; notifyAll(); &#125; &#125; @Autowired public void setHttpConnMgr(HttpClientConnectionManager httpConnMgr) &#123; this.httpConnMgr = httpConnMgr; &#125; public void setIdleSeconds(int idleSeconds) &#123; this.idleSeconds = idleSeconds; &#125;&#125; 附：HttpClientConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131@ConfigurationProperties(locations = \"classpath:system.properties\", prefix = \"http\")@Configurationpublic class HttpClientConfig &#123; private Integer connectionRequestTimeout; private Integer connectTimeout; private Integer socketTimeout; private Integer maxTotal; private Integer defaultMaxPerRoute; private boolean staleConnectionCheckEnabled; /** * 首先实例化一个连接池管理器，设置最大连接数、并发连接数 * @return */ @Bean(name = \"httpClientConnectionManager\") public PoolingHttpClientConnectionManager getHttpClientConnectionManager()&#123; PoolingHttpClientConnectionManager httpClientConnectionManager = new PoolingHttpClientConnectionManager(); //最大连接数 httpClientConnectionManager.setMaxTotal(maxTotal); //并发数 httpClientConnectionManager.setDefaultMaxPerRoute(defaultMaxPerRoute); return httpClientConnectionManager; &#125; /** * 实例化连接池，设置连接池管理器。 * 这里需要以参数形式注入上面实例化的连接池管理器 * @param httpClientConnectionManager * @return */ @Bean(name = \"httpClientBuilder\") public HttpClientBuilder getHttpClientBuilder(@Qualifier(\"httpClientConnectionManager\")PoolingHttpClientConnectionManager httpClientConnectionManager)&#123; //HttpClientBuilder中的构造方法被protected修饰，所以这里不能直接使用new来实例化一个HttpClientBuilder，可以使用HttpClientBuilder提供的静态方法create()来获取HttpClientBuilder对象 HttpClientBuilder httpClientBuilder = HttpClientBuilder.create(); httpClientBuilder.setConnectionManager(httpClientConnectionManager); return httpClientBuilder; &#125; /** * 注入连接池，用于获取httpClient * @param httpClientBuilder * @return */ @Bean public CloseableHttpClient getCloseableHttpClient(@Qualifier(\"httpClientBuilder\") HttpClientBuilder httpClientBuilder)&#123; return httpClientBuilder.build(); &#125; /** * Builder是RequestConfig的一个内部类 * 通过RequestConfig的custom方法来获取到一个Builder对象 * 设置builder的连接信息 * 这里还可以设置proxy，cookieSpec等属性。有需要的话可以在此设置 * @return */ @Bean(name = \"builder\") public RequestConfig.Builder getBuilder()&#123; RequestConfig.Builder builder = RequestConfig.custom(); return builder.setConnectTimeout(connectTimeout) .setConnectionRequestTimeout(connectionRequestTimeout) .setSocketTimeout(socketTimeout) .setStaleConnectionCheckEnabled(staleConnectionCheckEnabled); &#125; /** * 使用builder构建一个RequestConfig对象 * @param builder * @return */ @Bean public RequestConfig getRequestConfig(@Qualifier(\"builder\") RequestConfig.Builder builder)&#123; return builder.build(); &#125; public Integer getConnectionRequestTimeout() &#123; return connectionRequestTimeout; &#125; public void setConnectionRequestTimeout(Integer connectionRequestTimeout) &#123; this.connectionRequestTimeout = connectionRequestTimeout; &#125; public Integer getConnectTimeout() &#123; return connectTimeout; &#125; public void setConnectTimeout(Integer connectTimeout) &#123; this.connectTimeout = connectTimeout; &#125; public Integer getSocketTimeout() &#123; return socketTimeout; &#125; public void setSocketTimeout(Integer socketTimeout) &#123; this.socketTimeout = socketTimeout; &#125; public Integer getMaxTotal() &#123; return maxTotal; &#125; public void setMaxTotal(Integer maxTotal) &#123; this.maxTotal = maxTotal; &#125; public Integer getDefaultMaxPerRoute() &#123; return defaultMaxPerRoute; &#125; public void setDefaultMaxPerRoute(Integer defaultMaxPerRoute) &#123; this.defaultMaxPerRoute = defaultMaxPerRoute; &#125; public boolean isStaleConnectionCheckEnabled() &#123; return staleConnectionCheckEnabled; &#125; public void setStaleConnectionCheckEnabled(boolean staleConnectionCheckEnabled) &#123; this.staleConnectionCheckEnabled = staleConnectionCheckEnabled; &#125;&#125; system.preperties如下 12345678#HttpClient相关配置http.connectionRequestTimeout=2000http.connectTimeout=3000http.socketTimeout=20000http.maxTotal=70http.defaultMaxPerRoute=70http.staleConnectionCheckEnabled=truehttp.idleSeconds=30","categories":[{"name":"bug","slug":"bug","permalink":"http://yoursite.com/categories/bug/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"},{"name":"tcp","slug":"tcp","permalink":"http://yoursite.com/tags/tcp/"}]},{"title":"java对象模型","slug":"java对象模型","date":"2018-08-17T08:08:10.000Z","updated":"2018-09-05T02:37:10.732Z","comments":true,"path":"2018/08/17/java对象模型/","link":"","permalink":"http://yoursite.com/2018/08/17/java对象模型/","excerpt":"","text":"OOP-Klass模型KlassKlass简单的说是Java类在HotSpot中的c++对等体，用来描述Java类。 Klass主要有两个功能： 实现语言层面的Java类 实现Java对象的分发功能 一般jvm在加载class文件时，会在方法区创建instanceKlass，表示其元数据，包括常量池、字段、方法等。 OOPKlass是在class文件在加载过程中创建的，OOP则是在Java程序运行过程中new对象时创建的。 一个OOP对象包含以下几个部分： instanceOopDesc，也叫对象头 Mark Word，主要存储对象运行时记录信息，如hashcode, GC分代年龄，锁状态标志，线程ID，时间戳等 元数据指针，即指向方法区的instanceKlass实例 实例数据 内存存储关于一个Java对象，他的存储是怎样的，一般很多人会回答：对象存储在堆上。稍微好一点的人会回答：对象存储在堆上，对象的引用存储在栈上。今天，再给你一个更加显得牛逼的回答： 对象的实例（instantOopDesc)保存在堆上，对象的元数据（instantKlass）保存在方法区，对象的引用保存在栈上。 123456789101112131415class Model&#123; public static int a = 1; public int b; public Model(int b) &#123; this.b = b; &#125;&#125;public static void main(String[] args) &#123; int c = 10; Model modelA = new Model(2); Model modelB = new Model(3);&#125; 存储结构图如下： 从上图中可以看到，在方法区的instantKlass中有一个int a=1的数据存储。在堆内存中的两个对象的oop中，分别维护着int b=3,int b=2的实例数据。和oopDesc一样，instantKlass也维护着一些fields，用来保存类中定义的类数据，比如int a=1。 总结每一个Java类，在被JVM加载的时候，JVM会给这个类创建一个instanceKlass，保存在方法区，用来在JVM层表示该Java类。当我们在Java代码中，使用new创建一个对象的时候，JVM会创建一个instanceOopDesc对象，这个对象中包含了两部分信息，对象头以及实例数据。其中对象头结构如下 123456789class oopDesc &#123; friend class VMStructs; private: volatile markOop _mark; union _metadata &#123; wideKlassOop _klass; narrowOop _compressed_klass; &#125; _metadata;&#125; 上面代码中的_mark和_metadata其实就是对象头的定义 参考文档： java对象模型","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://yoursite.com/tags/虚拟机/"}]},{"title":"Mysql执行流程","slug":"mysql执行流程","date":"2018-08-16T01:33:40.000Z","updated":"2018-08-16T02:09:42.669Z","comments":true,"path":"2018/08/16/mysql执行流程/","link":"","permalink":"http://yoursite.com/2018/08/16/mysql执行流程/","excerpt":"","text":"大致可分为是个步骤 当我们请求mysql服务器的时候,MySQL前端会有一个监听,请求到了之后,服务器得到相关的SQL语句,执行之前(虚线部分为执行),还会做权限的判断 通过权限之后,SQL就到MySQL内部,他会在查询缓存中,看该SQL有没有执行过,如果有查询过,则把缓存结果返回,说明在MySQL内部,也有一个查询缓存.但是这个查询缓存,默认是不开启的,这个查询缓存,和我们的Hibernate，Mybatis的查询缓存是一样的,因为查询缓存要求SQL和参数都要一样,所以这个命中率是非常低的（没什么卵用的意思）。 如果我们没有开启查询缓存,或者缓存中没有找到对应的结果,那么就到了解析器,解析器主要对SQL语法进行解析 解析结束后就变成一颗解析树,这个解析树其实在Hibernate里面也是有的,大家回忆一下,在以前做过Hibernate项目的时候,是不是有个一个antlr.jar。这个就是专门做语法解析的工具.因为在Hibernate里面有HQL，它就是通过这个工具转换成SQL的,我们编程语言之所以有很多规范、语法,其实就是为了便于这个解析器解析,这个学过编译原理的应该知道. 得到解析树之后,不能马上执行,这还需要对这棵树进行预处理,也就是说,这棵树,我没有经过任何优化的树,预处理器会这这棵树进行一些预处理,比如常量放在什么地方,如果有计算的东西,把计算的结果算出来等等… 预处理完毕之后,此时得到一棵比较规范的树,这棵树就是要拿去马上做执行的树,比起之前的那棵树,这棵得到了一些优化 查询优化器，是MySQL里面最关键的东西,我们写任何一条SQL,比如SELECT * FROM USER WHERE USERNAME = toby AND PASSWORD = 1,它会怎么去执行?它是先执行username = toby还是password = 1?每一条SQL的执行顺序查询优化器就是根据MySQL对数据统计表的一些信息,比如索引,比如表一共有多少数据,MySQL都是有缓存起来的,在真正执行SQL之前,他会根据自己的这些数据,进行一个综合的判定,判断这一次在多种执行方式里面,到底选哪一种执行方式,可能运行的最快.这一步是MySQL性能中,最关键的核心点,也是我们的优化原则.我们平时所讲的优化SQL,其实说白了,就是想让查询优化器,按照我们的想法,帮我们选择最优的执行方案,因为我们比MySQL更懂我们的数据.MySQL看数据,仅仅只是自己收集到的信息,这些信息可能是不准确的,MySQL根据这些信息选了一个它自认为最优的方案,但是这个方案可能和我们想象的不一样. 这里的查询执行计划,也就是MySQL查询中的执行计划,比如要先执行username = toby还是password = 1 这个执行计划会传给查询执行引擎,执行引擎选择存储引擎来执行这一份传过来的计划,到磁盘中的文件中去查询,这个时候重点来了,影响这个查询性能最根本的原因是什么?就是硬盘的机械运动,也就是我们平时熟悉的IO,所以一条查询语句是快还是慢,就是根据这个时间的IO来确定的.那怎么执行IO又是什么来确定的?就是传过来的这一份执行计划. 如果开了查询缓存,则返回结果给客户端,并且查询缓存也放一份。 参考链接：mysql实行流程","categories":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Hexo 自带样式note标签","slug":"Hexo-自带样式note标签","date":"2018-08-09T03:11:36.000Z","updated":"2018-08-09T07:11:56.148Z","comments":true,"path":"2018/08/09/Hexo-自带样式note标签/","link":"","permalink":"http://yoursite.com/2018/08/09/Hexo-自带样式note标签/","excerpt":"","text":"主题自带样式 note 标签在主题配置文件_config.yml里有一个关于这个的配置，但官方文档没有提供 HTML 的使用方式，个人认为这种方式更简单，也不会产生一些奇怪的显示 bugs…… default &lt;div class=&quot;note default&quot;&gt;&lt;p&gt;default&lt;/p&gt;&lt;/div&gt; primary &lt;div class=&quot;note primary&quot;&gt;&lt;p&gt;primary&lt;/p&gt;&lt;/div&gt; success &lt;div class=&quot;note success&quot;&gt;&lt;p&gt;success&lt;/p&gt;&lt;/div&gt; info &lt;div class=&quot;note info&quot;&gt;&lt;p&gt;info&lt;/p&gt;&lt;/div&gt; warning &lt;div class=&quot;note warning&quot;&gt;&lt;p&gt;warning&lt;/p&gt;&lt;/div&gt; danger&lt;div class=&quot;note danger&quot;&gt;&lt;p&gt;danger&lt;/p&gt;&lt;/div&gt;danger no-icon &lt;div class=&quot;note danger no-icon&quot;&gt;&lt;p&gt;danger no-icon&lt;/p&gt;&lt;/div&gt; 首先可以在主题配置文件中需要配置下: 123456789# Note tag (bs-callout).note: # 风格 style: flat # 要不要图标 icons: true # 圆角矩形 border_radius: 3 light_bg_offset: 主题自带样式 代码块高亮样式用的是代码块，代码块的用法如下：[language] [title] [url] [link-text] [language] 是代码语言的名称，用来设置代码块颜色高亮，非必须； [title] 是顶部左边的说明，非必须； [url] 是顶部右边的超链接地址，非必须； [link text] 如它的字面意思，超链接的名称，非必须。 主题自带样式 文本居中引用人生乃是一面镜子，从镜子里认识自己，我要称之为头等大事，也只是我们追求的目的！ 源码：123456&#123;% cq %&#125;人生乃是一面镜子，从镜子里认识自己，我要称之为头等大事，也只是我们追求的目的！&#123;% endcq %&#125; 主题自带样式 tabs 标签示例源码： 1234567891011&#123;% tabs 选项卡, 2 %&#125;&lt;!-- tab --&gt;**这是选项卡 1** 1111&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 2** 2222222&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 3** 33333333&lt;!-- endtab --&gt;&#123;% endtabs %&#125; 效果：选项卡 1选项卡 2选项卡 3这是选项卡 1 1111 这是选项卡 2 2222222 这是选项卡 3 33333333 ,2 表示一开始在第二个选项卡，若为-1则隐藏 主题自带样式 label 标签{% label title@type %} type可以为下面几种defaultprimarysuccessinfowarningdanger 自定义样式 引用需要加入custom.styl的代码：文件位置：~/blog/themes/next/source/css/_custom/custom.styl123456789// 自定义的引用样式blockquote.question &#123; color: #555; border-left: 4px solid rgb(16, 152, 173); background-color: rgb(227, 242, 253); border-top-right-radius: 3px; border-bottom-right-radius: 3px; margin-bottom: 20px;&#125;","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"Hexo 文章的模板文件","slug":"Hexo-文章的模板文件","date":"2018-08-08T03:06:26.000Z","updated":"2018-08-08T03:21:51.205Z","comments":true,"path":"2018/08/08/Hexo-文章的模板文件/","link":"","permalink":"http://yoursite.com/2018/08/08/Hexo-文章的模板文件/","excerpt":"","text":"如果你是在站点文件夹根目录用 hexo new post &lt;title&gt; 新建的文章，那么其实它就是将文章的模版文件post.md“复制”了一份到~/blog/source/_posts/下，所以这也意味着： 你可以直接通过在~/blog/source/_posts/下新建.md结尾的文件来写新的文章。 你可以通过自定义文章的模版文件，从而每次命令行新建的文章都会有你自定义的内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* ！！！！！！！！！！** 每一项的 : 后面均有一个空格** 且 : 为英文符号** ！！！！！！！！！！*/title:/* 文章标题，可以为中文 */date:/* 建立日期，如果自己手动添加，请按固定格式** 就算不写，页面每篇文章顶部的发表于……也能显示** 只要在主题配置文件中，配置了 created_at 就行** 那为什么还要自己加上？** 自定义文章发布的时间*/updated:/* 更新日期，其它与上面的建立日期类似** 不过在页面每篇文章顶部，是更新于……** 在主题配置文件中，是 updated_at*/permalink:/* 若站点配置文件下的 permalink 配置了 title** 则可以替换文章 URL 里面的 title（文章标题）*/categories:/* 分类，支持多级，比如：- technology- computer- computer-aided-art则为technology/computer/computer-aided-art（不适用于 layout: page）*/tags:/* 标签** 多个可以这样写[标签1,标签2,标签3]** （不适用于 layout: page）*/description:/* 文章的描述，在每篇文章标题下方显示** 并且作为网页的 description 元数据** 如果不写，则自动取 &lt;!-- more --&gt;** 之前的文字作为网页的 description 元数据** 建议每篇文章都务必加上！*/keywords:/* 关键字，并且作为网页的 keywords 元数据** 如果不写，则自动取 tags 里的项** 作为网页的 keywords 元数据*/comments:/* 是否开启评论** 默认值是 true** 要关闭写 false*/layout:/* 页面布局，默认值是 post，默认值可以在** 站点配置文件中修改 default_layout** 另：404 页面可能用到，将其值改为 false*/type:/* categories，目录页面** tags，标签页面** picture，用来生成 group-pictures** quote？** https://reuixiy.github.io/uncategorized/2010/01/01/test.html*/photos:/* Gallery support，用来支持画廊 / 相册，用法如下：- photo_url_1- photo_url_2- photo_url_3https://reuixiy.github.io/uncategorized/2010/01/01/test.html*/link:/* 文章的外部链接** https://reuixiy.github.io/uncategorized/2010/01/01/test.html*/image:/* 自定义的文章摘要图片，只在页面展示，文章内消失** 此项只有参考本文 5.14 节配置好，否则请勿添加！*/sticky:/* 文章置顶** 此项只有参考本文 5.15 节配置好，否则请勿添加！*/password:/* 文章密码，此项只有参考教程：** http://shenzekun.cn/hexo的next主题个性化配置教程.html** 第 24 节，配置好，否则请勿添加！** 发现还是有 bug 的，就是右键在新标签中打开** 然后无论是否输入密码，都能看到内容*/","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"深入java虚拟机_第三章 垃圾收集器与内存分配策略","slug":"深入java虚拟机-第三章-垃圾收集器与内存分配策略","date":"2018-08-07T06:38:23.000Z","updated":"2018-08-09T03:12:59.651Z","comments":true,"path":"2018/08/07/深入java虚拟机-第三章-垃圾收集器与内存分配策略/","link":"","permalink":"http://yoursite.com/2018/08/07/深入java虚拟机-第三章-垃圾收集器与内存分配策略/","excerpt":"","text":"垃圾收集器与内存分配策略对象存活判定垃圾收集算法 标记-清楚算法算法分为“标记”和“清除”两个阶段两个不足：1、效率，标记和清除两个过程效率都不高2、空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前出发另一次垃圾收集动作。 复制算法解决效率问题，将内存分两个区域，复制收集算法在对象存活率较高时就要进行较多的复制操作，效率会变低，老年代一般不能直接选用这种算法 标记-整理算法过程与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都想一端移动，然后直接清理掉边界以外的内存 分代收集算法根据对象存货周期的不同将内存划分为几块。一般是把java堆分为新生代和老年代，这样可以根据各个年代的特点采用最适当的手机算法。新生代采用复制算法，老年代使用“标记-清理”或者“标记-整理” HotSpot算法实现GC停顿、OopMap、安全点、抢先试中断、主动式中断、安全区域 垃圾收集器 Serial收集器最基本，发展历史最悠久。在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。缺点：需要停顿，用户体验不良优点：简单而高效，没有线程交互的开销，对于运行在Client模式下的虚拟机来说是一个很好的选择 ParNew收集器Serial收集器的多线程版本，运行在Server模式下的虚拟机中首选的新生代收集器，除了Serial收集器外，目前只有它能与CMS收集器配合工作 Parallel Scavenge收集器新生代收集器，使用复制算法，并行的多线程收集器特点：它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量，即CPU用于运行用户代码的时间与CPU总消耗时间的比值两个参数，精确控制吞吐量：最大垃圾收集停顿时间-XX:MaxGCPauseMills，，吞吐量大小：-XX:GCTimeRatio-XX:+UseAdaptiveSizePolicy是一个开关参数，动态调整，自适应调节策略 Serial Old收集器是Serial收集器的老年代版本，使用 标记-整理 算法 Parallel Old收集器是Parallel Scavenge收集器的老年代版本 使用多线程和标记-整理算法Parallel Scavenge + Parallel Old CMS收集器（Concurrent Mark Sweep）是一种以获取最短回收时间为目标的收集器基于标记-清除算法，过程分4个步骤：1、初始标记CMS initial mark2、并发标记CMS concurrent mark3、重新标记CMS remark4、并发清除CMS concurrent sweep优点：并发收集、低停顿缺点：CMS收集器对CPU资源非常敏感、CMS收集器无法处理浮动垃圾、空间碎片整理 G1收集器是一款面向服务端应用的垃圾收集器特点：1、并行与并发2、分代收集3、空间整合4、可预测的停顿","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://yoursite.com/tags/虚拟机/"}]},{"title":"计算机网络面试","slug":"计算机网络面试","date":"2018-08-02T02:59:33.000Z","updated":"2018-08-20T01:16:33.698Z","comments":true,"path":"2018/08/02/计算机网络面试/","link":"","permalink":"http://yoursite.com/2018/08/02/计算机网络面试/","excerpt":"","text":"一 OSI与TCP/IP各层的结构与功能,都有哪些协议五层协议的体系结构学习计算机网络时我们一般采用折中的办法，也就是中和OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。 结合互联网的情况，自上而下地，非常简要的介绍一下各层的作用。 1 应用层应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议等等。我们把应用层交互的数据单元称为报文。 域名系统 域名系统(Domain Name System缩写DNS，Domain Name被译为域名)是因特网的一项核心服务，它作为可以将域名和IP地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。（百度百科）例如：一个公司的Web网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM公司的域名是www.ibm.com、Oracle公司的域名是www.oracle.com、Cisco公司的域名是www.cisco.com等。 HTTP协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。（百度百科） 2 运输层运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。 运输层主要使用以下两种协议 传输控制协议TCP（Transmisson Control Protocol）–提供面向连接的，可靠的数据传输服务。 用户数据协议UDP（User Datagram Protocol）–提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。 UDP的主要特点 UDP是无连接的； UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）； UDP是面向报文的； UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）； UDP支持一对一、一对多、多对一和多对多的交互通信； UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 TCP的主要特点 TCP是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）； TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达； TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 面向字节流。TCP中的“流”（stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 3 网络层网络层(network layer)负责为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在TCP/IP体系结构中，由于网络层使用IP协议，因此分组也叫IP数据报，简称数据报。 这里要注意：不要把运输层的“用户数据报UDP”和网络层的“IP数据报”弄混。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。 网络层的另一个任务就是选择合适的路由，使源主机运输层所传下来的分株，能通过网络层中的路由器找到目的主机。 这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称. 互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Prococol）和许多路由选择协议，因此互联网的网络层也叫做网际层或IP层。 4 数据链路层数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的IP数据报组装程帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。 在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。 控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。 5 物理层在物理层上所传送的数据单位是比特。物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 在互联网使用的各种协中最重要和最著名的就是TCP/IP两个协议。现在人们经常提到的TCP/IP并不一定单指TCP和IP这两个具体的协议，而往往表示互联网所使用的整个TCP/IP协议族。 上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下。 二 TCP三次握手和四次挥手(面试常客)为了准确无误地把数据送达目标处，TCP协议采用了三次握手策略。 漫画图解： 图片来源：《图解HTTP》 简单示意图： 客户端–发送带有SYN标志的数据包–一次握手–服务端 服务端–发送带有SYN/ACK标志的数据包–二次握手–客户端 客户端–发送带有带有ACK标志的数据包–三次握手–服务端 为什么要三次握手三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。 第一次握手：Client什么都不能确认；Server确认了对方发送正常 第二次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：自己接收正常，对方发送正常 第三次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：自己发送、接收正常，对方发送接收正常 所以三次握手就能确认双发收发功能都正常，缺一不可。 为什么要传回syn接收端传回发送端所发送的SYN是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。 传了SYN,为啥还要传ACK双方通信无误必须是两者互相发送信息都无误。传了SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要ACK信号来进行验证。 断开一个TCP连接则需要“四次挥手”： 客户端-发送一个FIN，用来关闭客户端到服务器的数据传送 服务器-收到这个FIN，它发回一个ACK，确认序号为收到的序号加1 。和SYN一样，一个FIN将占用一个序号 服务器-关闭与客户端的连接，发送一个FIN给客户端 客户端-发回ACK报文确认，并将确认序号设置为收到序号加1 为什么要四次挥手任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。 举个例子：A和B打电话，通话即将结束后，A说“我没啥要说的了”，B回答“我知道了”，但是B可能还会有要说的话，A不能要求B跟着自己的节奏结束通话，于是B可能又巴拉巴拉说了一通，最后B说“我说完了”，A回答“知道了”，这样通话才算结束。 上面讲的比较概括，推荐一篇讲的比较细致的文章：https://blog.csdn.net/qzcsu/article/details/72861891 三 TCP、UDP协议的区别 UDP在传送数据之前不需要先建立连接，远地主机在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP确是一种最有效的工作方式（一般用于即时通信），比如： QQ语音 QQ视频 、直播等等 TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的，面向连接的运输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP一般用于文件传输、发送和接收邮件、远程登录等场景。 四 TCP协议如何保证可靠传输 应用数据被分割成TCP认为最适合发送的数据块。 超时重传： 当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 TCP的接收端会丢弃重复的数据。 流量控制： TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的我数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。 （TCP利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 停止等待ARQ协议（stop and wait） 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续ARQ协议可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 停止等待协议 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停下来等待对方确认。这样可使信道上一直有数据不间断的在传送。这种传输方式可以明显提高信道利用率。 滑动窗口TCP利用滑动窗口实现流量控制的机制。 发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分表示已发送且已收到确认，而发送窗口前沿的前面部分表示不晕与发送。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口的前沿通常是不断向前移动的。一般来说，我们总是希望数据传输更快一些。但如果发送方把数据发送的过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 流量控制流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。 为了进行拥塞控制，TCP发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理AQM），以减少网络拥塞的发生。 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。 拥塞避免： 拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1. 快重传与快恢复： 在TCP/IP中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有FRR，如果数据包丢失了，TCP将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了FRR，就不会因为重传时要求的暂停被耽误。 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 五 在浏览器中输入url地址 -&gt;&gt; 显示主页的过程（面试常客）百度好像最喜欢问这个问题。 打开一个网页，整个过程会使用哪些协议 图片来源：《图解HTTP》 六 状态码 七 各种协议与HTTP协议之间的关系一般面试官会通过这样的问题来考察你对计算机网络知识体系的理解。 图片来源：《图解HTTP》 八 HTTP长连接、短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 —— 《HTTP长连接、短连接究竟是什么？》 写在最后计算机网络常见问题回顾 ①TCP三次握手和四次挥手、 ②在浏览器中输入url地址-&gt;&gt;显示主页的过程 ③HTTP和HTTPS的区别 ④TCP、UDP协议的区别 ⑤常见的状态码。 建议非常推荐大家看一下 《图解HTTP》 这本书，这本书页数不多，但是内容很是充实，不管是用来系统的掌握网络方面的一些知识还是说纯粹为了应付面试都有很大帮助。下面的一些文章只是参考。大二学习这门课程的时候，我们使用的教材是 《计算机网络第七版》（谢希仁编著），不推荐大家看这本教材，书非常厚而且知识偏理论，不确定大家能不能心平气和的读完。 原文地址：计算机网络面试","categories":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/categories/面试/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://yoursite.com/tags/计算机网络/"},{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"【转】String类和常量池","slug":"tags","date":"2018-08-02T02:53:24.000Z","updated":"2018-08-23T02:34:57.871Z","comments":true,"path":"2018/08/02/tags/","link":"","permalink":"http://yoursite.com/2018/08/02/tags/","excerpt":"","text":"String对象的两种创建方式123String str1 = \"abcd\";String str2 = new String(\"abcd\");System.out.println(str1==str2);//false 这两种不同的创建方法是有差别的，第一种方式是在常量池中拿对象，第二种方式是直接在堆内存空间创建一个新的对象。 记住： 只要使用new方法，便需要创建新的对象 String类型的常量池 直接使用双引号声明出来的 String 对象会直接存储在常量池中。 如果不是用双引号声明的 String 对象，可以使用 String 提供的 intern 方String.intern()是一个 Native 方法，它的作用是：如果运行时常量池中已经包含一个等于此 String 对象内容的字符串，则返回常量池中该字符串的引用；如果没有，则在常量池中创建与此 String 内容相同的字符串，并返回常量池中创建的字符串的引用。 123456String s1 = new String(\"计算机\");String s2 = s1.intern();String s3 = \"计算机\";System.out.println(s2);//计算机System.out.println(s1 == s2);//false，因为一个是堆内存中的String对象一个是常量池中的String对象，System.out.println(s3 == s2);//true，因为两个都是常量池中的String对 String字符串的拼接12345678String str1 = \"str\";String str2 = \"ing\";String str3 = \"str\" + \"ing\";//常量池中的对象String str4 = str1 + str2; //在堆上创建的新的对象 String str5 = \"string\";//常量池中的对象System.out.println(str3 == str4);//falseSystem.out.println(str3 == str5);//trueSystem.out.println(str4 == str5);//false 尽量避免多个字符串拼接，因为这样会重新创建对象。如果需要改变字符串的花，可以使用 StringBuilder 或者 StringBuffer。 String s1 = new String(“abc”)创建了两个对象 1234String s1 = new String(\"abc\");// 堆内存的地值值 String s2 = \"abc\"; System.out.println(s1 == s2);// 输出false,因为一个是堆内存，一个是常量池的内存，故两者是不同的。 System.out.println(s1.equals(s2));// 输出true 先有字符串”abc”放入常量池，然后 new 了一份字符串”abc”放入Java堆(字符串常量”abc”在编译期就已经确定放入常量池，而 Java 堆上的”abc”是在运行期初始化阶段才确定)，然后 Java 栈的 str1 指向Java堆上的”abc”。 String不可变类我们知道在Java中，String是不可变的、final的。Java在运行时也保存了一个字符串池(String pool)，这使得String成为了一个特别的类。 String类不可变性的好处 只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多 heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String interning将不能实现(译者注：String interning是指对不同的字符串仅仅只保存一个，即不会保存多个相同的字符串。)，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变。 如果字符串是可变的，那么会引起很严重的安全问题。譬如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。因为字符串是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变字符串指向的对象的值，造成安全漏洞。 因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。 类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。譬如你想加载java.sql.Connection类，而这个值被改成了myhacked.Connection，那么会对你的数据库造成不可知的破坏。 因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。 参考文章：java内存区域","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"【转】内存模型是怎么解决缓存一致性的","slug":"内存模型是怎么解决缓存一致性的","date":"2018-08-02T01:39:30.000Z","updated":"2018-08-20T01:36:04.812Z","comments":true,"path":"2018/08/02/内存模型是怎么解决缓存一致性的/","link":"","permalink":"http://yoursite.com/2018/08/02/内存模型是怎么解决缓存一致性的/","excerpt":"","text":"在再有人问你Java内存模型是什么，就把这篇文章发给他这篇文章中，我们介绍过关于Java内存模型的来龙去脉。 我们在文章中提到过，由于CPU和主存的处理速度上存在一定差别，为了匹配这种差距，提升计算机能力，人们在CPU和主存之间增加了多层高速缓存。每个CPU会有L1、L2甚至L3缓存，在多核计算机中会有多个CPU，那么就会存在多套缓存，那么这多套缓存之间的数据就可能出现不一致的现象。为了解决这个问题，有了内存模型。内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。 不知道小伙伴们有没有想过这样的问题：内存模型到底是怎么保证缓存一致性的呢？ 接下来我们试着回答这个问题。首先，缓存一致性是由于引入缓存而导致的问题，所以，这是很多CPU厂商必须解决的问题。为了解决前面提到的缓存数据不一致的问题，人们提出过很多方案，通常来说有以下2种方案： 1、通过在总线加LOCK#锁的方式。 2、通过缓存一致性协议（Cache Coherence Protocol）。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从其内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是由于在锁住总线期间，其他CPU无法访问内存，会导致效率低下。因此出现了第二种解决方案，通过缓存一致性协议来解决缓存一致性问题。 缓存一致性协议缓存一致性协议（Cache Coherence Protocol），最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。 MESI的核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 在MESI协议中，每个缓存可能有有4个状态，它们分别是： M(Modified)：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 E(Exclusive)：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。 S(Shared)：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。 I(Invalid)：这行数据无效。 关于MESI的更多细节这里就不详细介绍了，读者只要知道，MESI是一种比较常用的缓存一致性协议，他可以用来解决缓存之间的数据一致性问题就可以了。 但是，值得注意的是，传统的MESI协议中有两个行为的执行成本比较大。 一个是将某个Cache Line标记为Invalid状态，另一个是当某Cache Line当前状态为Invalid时写入新的数据。所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时。 如图： 当一个CPU进行写入时，首先会给其它CPU发送Invalid消息，然后把当前写入的数据写入到Store Buffer中。然后异步在某个时刻真正的写入到Cache中。 当前CPU核如果要读Cache中的数据，需要先扫描Store Buffer之后再读取Cache。 但是此时其它CPU核是看不到当前核的Store Buffer中的数据的，要等到Store Buffer中的数据被刷到了Cache之后才会触发失效操作。 而当一个CPU核收到Invalid消息时，会把消息写入自身的Invalidate Queue中，随后异步将其设为Invalid状态。 和Store Buffer不同的是，当前CPU核心使用Cache时并不扫描Invalidate Queue部分，所以可能会有极短时间的脏读问题。 所以，为了解决缓存的一致性问题，比较典型的方案是MESI缓存一致性协议。 MESI协议，可以保证缓存的一致性，但是无法保证实时性。 内存模型前面介绍过了缓存一致性模型，接着我们再来看一下内存模型。我们说过内存模型定义一系列规范，来保证多线程访问共享变量时的可见性、有序性和原子性。（更多内容请参考再有人问你Java内存模型是什么，就把这篇文章发给他。） 内存模型（Memory Model）如果扩展开来说的话，通常指的是内存一致性模型（Memory Sequential Consistency Model） 前面我们提到过缓存一致性，这里又要说内存一致性，不是故意要把读者搞蒙，而是希望通过对比让读者更加清楚。 缓存一致性（Cache Coherence），解决是多个缓存副本之间的数据的一致性问题。 内存一致性（Memory Consistency），保证的是多线程程序访问内存时可以读到什么值。 我们首先看以下程序： 1初始：x=0 y=0Thread1：S1：x=1L1：r1=yThread2：S2：y=2L2：r2=x 其中，S1、S2、L1、L2是语句代号（S表示Store，L表示Load）；r1和r2是两个寄存器。x和y是两个不同的内存变量。两个线程执行完之后，r1和r2可能是什么值？ 注意到线程是并发、交替执行的，下面是可能的执行顺序和相应结果： 1S1 L1 S2 L2 那么r1=0 r2=2S1 S2 L1 L2 那么r1=2 r2=1S2 L2 S1 L1 那么r1=2 r2=0 这些都是意料之内、情理之中的。但是在x86体系结构下，很可能得到r1=0 r2=0这样的结果。 如果没有Memory Consistency，程序员写的程序代码的输出结果是不确定的。 因此，Memory Consistency就是程序员（编程语言）、编译器、CPU间的一种协议。这个协议保证了程序访问内存时会得到什么值。 简单点说，内存一致性，就是保证并发场景下的程序运行结果和程序员预期是一样的（当然，要通过加锁等方式），包括的就是并发编程中的原子性、有序性和可见性。而缓存一致性说的就是并发编程中的可见性。 在很多内存模型的实现中，关于缓存一致性的保证都是通过硬件层面缓存一致性协议来保证的。需要注意的是，这里提到的内存模型，是计算机内存模型，而非Java内存模型。 总结缓存一致性问题。硬件层面的问题，指的是由于多核计算机中有多套缓存，各个缓存之间的数据不一致性问题。 PS：这里还需要再重复一遍，Java多线程中，每个线程都有自己的工作内存，需要和主存进行交互。这里的工作内存和计算机硬件的缓存并不是一回事儿，只是可以相互类比。所以，并发编程的可见性问题，是因为各个线程之间的本地内存数据不一致导致的，和计算机缓存并无关系。 缓存一致性协议。用来解决缓存一致性问题的，常用的是MESI协议。 内存一致性模型。屏蔽计算机硬件问题，主要来解决并发编程中的原子性、有序性和一致性问题。 实现内存一致性模型的时候可能会用到缓存一致性模型。 原文地址：内存模型是怎么解决缓存一致性的？","categories":[{"name":"java","slug":"java","permalink":"http://yoursite.com/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://yoursite.com/tags/java虚拟机/"}]},{"title":"你好,Hexo","slug":"你好-Hexo","date":"2018-08-02T01:05:11.000Z","updated":"2018-08-02T01:15:02.302Z","comments":true,"path":"2018/08/02/你好-Hexo/","link":"","permalink":"http://yoursite.com/2018/08/02/你好-Hexo/","excerpt":"","text":"阿斯达所大所多","categories":[],"tags":[]}]}